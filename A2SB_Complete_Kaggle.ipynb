{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸµ A2SB: Ses Restorasyonu - Kaggle\n",
    "\n",
    "**NVIDIA A2SB ile YÃ¼ksek Kaliteli Ses Restorasyonu**\n",
    "\n",
    "Bu notebook ile ses dosyalarÄ±nÄ±zÄ± AI ile restore edebilirsiniz!\n",
    "\n",
    "## ğŸš€ Ã–zellikler\n",
    "- âœ… 44.1kHz yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼ ses restorasyonu\n",
    "- âœ… Bandwidth extension (yÃ¼ksek frekans tahmini)\n",
    "- âœ… Audio inpainting (eksik kÄ±sÄ±mlarÄ± doldurma)\n",
    "- âœ… KullanÄ±cÄ± dostu Gradio arayÃ¼zÃ¼\n",
    "\n",
    "## ğŸ“‹ Gereksinimler\n",
    "- ğŸ¯ **GPU**: P100 (16GB) Ã¶nerilir\n",
    "- ğŸ’¾ **RAM**: Minimum 25GB\n",
    "- â±ï¸ **SÃ¼re**: 10 saniyelik ses iÃ§in ~2-3 dakika\n",
    "\n",
    "## âš™ï¸ GPU NasÄ±l EtkinleÅŸtirilir?\n",
    "1. SaÄŸ tarafta **Settings** (Ayarlar) tÄ±klayÄ±n\n",
    "2. **Accelerator** altÄ±nda **GPU P100** seÃ§in\n",
    "3. **Save** (Kaydet) tÄ±klayÄ±n\n",
    "\n",
    "## ğŸ“š Kaynaklar\n",
    "- ğŸ“„ [Paper](https://arxiv.org/abs/2501.11311)\n",
    "- ğŸ’» [GitHub](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- ğŸ¤— [Models](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
    "\n",
    "---\n",
    "\n",
    "**KullanÄ±m:** HÃ¼creleri sÄ±rayla Ã§alÄ±ÅŸtÄ±rÄ±n!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ AdÄ±m 1: CUDA UyumluluÄŸunu DÃ¼zelt (Ã–NEMLÄ°!)\n",
    "\n",
    "**âš ï¸ Ä°LK Ã–NCE BUNU Ã‡ALIÅTIRIN!**\n",
    "\n",
    "Kaggle'da PyTorch CUDA 11.8 ama torchvision CUDA 12.4 ile geliyor. Bu uyumsuzluk hatasÄ± veriyor.\n",
    "\n",
    "**Bu hÃ¼cre:**\n",
    "1. Uyumsuz paketleri kaldÄ±rÄ±r\n",
    "2. CUDA 11.8 uyumlu versiyonlarÄ± yÃ¼kler\n",
    "3. UyumsuzluÄŸu dÃ¼zeltir\n",
    "\n",
    "**â±ï¸ 2-3 dakika sÃ¼rer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ğŸ”§ CUDA UYUMSUZLUÄU DÃœZELTÄ°LÄ°YOR\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nâš ï¸ Bu Kaggle uyumluluÄŸu iÃ§in KRÄ°TÄ°K!\")\n",
    "print(\"â±ï¸  2-3 dakika sÃ¼recek...\\n\")\n",
    "\n",
    "# AdÄ±m 1: Uyumsuz paketleri kaldÄ±r\n",
    "print(\"ğŸ“¦ AdÄ±m 1/4: Uyumsuz paketler kaldÄ±rÄ±lÄ±yor...\")\n",
    "!pip uninstall -y torch torchvision torchaudio torchmetrics transformers torchao -q\n",
    "print(\"âœ“ Eski paketler kaldÄ±rÄ±ldÄ±\\n\")\n",
    "\n",
    "# AdÄ±m 2: PyTorch CUDA 11.8 ile yÃ¼kle\n",
    "print(\"ğŸ“¦ AdÄ±m 2/4: PyTorch CUDA 11.8 yÃ¼kleniyor...\")\n",
    "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 \\\n",
    "    --index-url https://download.pytorch.org/whl/cu118 -q\n",
    "print(\"âœ“ PyTorch yÃ¼klendi\\n\")\n",
    "\n",
    "# AdÄ±m 3: Uyumlu torchmetrics yÃ¼kle\n",
    "print(\"ğŸ“¦ AdÄ±m 3/4: Torchmetrics yÃ¼kleniyor...\")\n",
    "!pip install torchmetrics==1.2.0 --no-deps -q\n",
    "!pip install numpy packaging -q\n",
    "print(\"âœ“ Torchmetrics yÃ¼klendi\\n\")\n",
    "\n",
    "# AdÄ±m 4: Lightning yÃ¼kle\n",
    "print(\"ğŸ“¦ AdÄ±m 4/4: Lightning yÃ¼kleniyor...\")\n",
    "!pip install lightning==2.1.0 pytorch-lightning==2.1.0 -q\n",
    "print(\"âœ“ Lightning yÃ¼klendi\\n\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"âœ… CUDA DÃœZELTMESÄ° TAMAMLANDI!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nâš ï¸ Ã–NEMLÄ°: Åimdi kernel'Ä± yeniden baÅŸlatmalÄ±sÄ±nÄ±z!\")\n",
    "print(\"\\nğŸ‘‰ Session > Restart Session\")\n",
    "print(\"\\nYeniden baÅŸlattÄ±ktan sonra AdÄ±m 2'den devam edin (bu hÃ¼creyi atlayÄ±n).\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš ï¸ KERNEL'I ÅÄ°MDÄ° YENÄ°DEN BAÅLATIN!\n",
    "\n",
    "**YukarÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rdÄ±ktan sonra:**\n",
    "1. **Session > Restart Session** gidin\n",
    "2. Kernel'Ä±n yeniden baÅŸlamasÄ±nÄ± bekleyin\n",
    "3. AÅŸaÄŸÄ±daki AdÄ±m 2'den devam edin\n",
    "4. AdÄ±m 1'i **TEKRAR Ã‡ALIÅTIRMAYIN**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… AdÄ±m 2: Kurulumu DoÄŸrula (Kernel Yeniden BaÅŸladÄ±ktan Sonra)\n",
    "\n",
    "**CUDA dÃ¼zeltmesinin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± doÄŸrulayalÄ±m.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ” KURULUM DOÄRULANIYOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nâœ“ PyTorch: {torch.__version__}\")\n",
    "print(f\"âœ“ PyTorch CUDA: {torch.version.cuda}\")\n",
    "print(f\"âœ“ CUDA Mevcut: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nâœ“ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"âœ“ GPU Bellek: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    if 'P100' in torch.cuda.get_device_name(0):\n",
    "        print(\"\\nğŸ‰ MÃ¼kemmel! P100 GPU var!\")\n",
    "    \n",
    "    if gpu_memory < 14:\n",
    "        print(f\"\\nâš ï¸ UyarÄ±: GPU sadece {gpu_memory:.1f} GB belleÄŸe sahip\")\n",
    "        print(\"Ã–nerilen: Settings'den P100 GPU (16GB) etkinleÅŸtirin\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… GPU belleÄŸi yeterli ({gpu_memory:.1f} GB)\")\n",
    "else:\n",
    "    print(\"\\nâŒ HATA: CUDA mevcut deÄŸil!\")\n",
    "    print(\"LÃ¼tfen Settings > Accelerator > GPU P100 etkinleÅŸtirin\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if torch.version.cuda == \"11.8\":\n",
    "    print(f\"\\nâœ… CUDA versiyonu doÄŸru: {torch.version.cuda}\")\n",
    "    print(\"âœ… Uyumsuzluk yok - Devam edebilirsiniz!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ UyarÄ±: PyTorch CUDA versiyonu {torch.version.cuda}\")\n",
    "    print(\"Beklenen: 11.8\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… DOÄRULAMA TAMAMLANDI!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ AdÄ±m 3: BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kle\n",
    "\n",
    "**Ses restorasyonu iÃ§in gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyelim.**\n",
    "\n",
    "**â±ï¸ 3-5 dakika sÃ¼rer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“¦ BaÄŸÄ±mlÄ±lÄ±klar yÃ¼kleniyor...\\n\")\n",
    "\n",
    "# Ses iÅŸleme kÃ¼tÃ¼phaneleri\n",
    "print(\"ğŸ“¥ Ses iÅŸleme kÃ¼tÃ¼phaneleri...\")\n",
    "!pip install librosa soundfile scipy einops -q\n",
    "print(\"âœ“ Ses kÃ¼tÃ¼phaneleri yÃ¼klendi\\n\")\n",
    "\n",
    "# KonfigÃ¼rasyon araÃ§larÄ±\n",
    "print(\"ğŸ“¥ KonfigÃ¼rasyon araÃ§larÄ±...\")\n",
    "!pip install jsonargparse[signatures] pyyaml -q\n",
    "print(\"âœ“ KonfigÃ¼rasyon araÃ§larÄ± yÃ¼klendi\\n\")\n",
    "\n",
    "# Gradio ve yardÄ±mcÄ± araÃ§lar\n",
    "print(\"ğŸ“¥ Gradio ve yardÄ±mcÄ± araÃ§lar...\")\n",
    "!pip install 'huggingface_hub>=0.19.0,<1.0' -q\n",
    "!pip install gradio==4.44.0 -q\n",
    "!pip install nest-asyncio tqdm rotary-embedding-torch pyngrok -q\n",
    "print(\"âœ“ Gradio yÃ¼klendi\\n\")\n",
    "\n",
    "# Opsiyonel: SSR Eval\n",
    "!pip install ssr-eval -q 2>/dev/null || echo \"âš ï¸ SSR Eval atlandÄ± (opsiyonel)\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… TÃœM BAÄIMLILIKLAR YÃœKLENDÄ°!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# DoÄŸrulama\n",
    "import torch\n",
    "import lightning\n",
    "import gradio as gr\n",
    "import librosa\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(f\"\\nâœ“ PyTorch: {torch.__version__}\")\n",
    "print(f\"âœ“ Lightning: {lightning.__version__}\")\n",
    "print(f\"âœ“ Gradio: {gr.__version__}\")\n",
    "print(f\"âœ“ Librosa: {librosa.__version__}\")\n",
    "print(\"\\nğŸ‰ Devam etmeye hazÄ±r!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ AdÄ±m 4: Repository'yi Klonla\n",
    "\n",
    "**Ses restorasyonu kodunu indirelim.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"ğŸ“¥ Repository klonlanÄ±yor...\\n\")\n",
    "\n",
    "os.chdir('/kaggle/working')\n",
    "!rm -rf diffusion-audio-restoration-colab-Kaggle-\n",
    "!git clone https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git\n",
    "os.chdir('diffusion-audio-restoration-colab-Kaggle-')\n",
    "\n",
    "print(f\"\\nâœ… Repository klonlandÄ±!\")\n",
    "print(f\"âœ“ Dizin: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤— AdÄ±m 5: Modelleri Ä°ndir\n",
    "\n",
    "**Hugging Face'den iki model checkpoint'i indirelim:**\n",
    "- One-split (0.0-1.0): ~1.5GB\n",
    "- Two-split (0.5-1.0): ~1.5GB\n",
    "\n",
    "**Toplam: ~3GB. 5-10 dakika sÃ¼rer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "print(\"ğŸ¤— Modeller Hugging Face'den indiriliyor...\")\n",
    "print(\"â±ï¸  5-10 dakika sÃ¼recek...\\n\")\n",
    "\n",
    "model_dir = './pretrained_models'\n",
    "\n",
    "try:\n",
    "    snapshot_download(\n",
    "        repo_id='nvidia/audio_to_audio_schrodinger_bridge',\n",
    "        local_dir=model_dir,\n",
    "        local_dir_use_symlinks=False\n",
    "    )\n",
    "    print(f\"\\nâœ… Modeller indirildi: {model_dir}\")\n",
    "    print(f\"\\nğŸ“‚ Model dosyalarÄ±:\")\n",
    "    !ls -lh {model_dir}\n",
    "    print(\"\\nâœ… Model indirme tamamlandÄ±!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Model indirme hatasÄ±: {e}\")\n",
    "    print(\"\\nSorun Giderme:\")\n",
    "    print(\"1. Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin\")\n",
    "    print(\"2. Hugging Face'e eriÅŸilebildiÄŸini doÄŸrulayÄ±n\")\n",
    "    print(\"3. Bu hÃ¼creyi tekrar Ã§alÄ±ÅŸtÄ±rÄ±n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”‘ AdÄ±m 6: Ngrok Token (Opsiyonel ama Ã–nerilir)\n",
    "\n",
    "**Ngrok, Gradio arayÃ¼zÃ¼nÃ¼z iÃ§in stabil bir public URL saÄŸlar.**\n",
    "\n",
    "### Ngrok token nasÄ±l alÄ±nÄ±r:\n",
    "1. [ngrok.com](https://ngrok.com/) gidin\n",
    "2. Ãœcretsiz hesap oluÅŸturun\n",
    "3. [Dashboard](https://dashboard.ngrok.com/get-started/your-authtoken) gidin\n",
    "4. Authtoken'Ä±nÄ±zÄ± kopyalayÄ±n\n",
    "5. AÅŸaÄŸÄ±ya yapÄ±ÅŸtÄ±rÄ±n\n",
    "\n",
    "**Not:** Ngrok token olmadan Gradio varsayÄ±lan paylaÅŸÄ±mÄ± kullanÄ±r (bu da Ã§alÄ±ÅŸÄ±r)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Ngrok token'Ä±nÄ±zÄ± buraya yapÄ±ÅŸtÄ±rÄ±n (opsiyonel)\n",
    "NGROK_TOKEN = \"\"  # Ã–rnek: \"2abc123def456ghi789jkl\"\n",
    "\n",
    "if NGROK_TOKEN:\n",
    "    os.environ['NGROK_TOKEN'] = NGROK_TOKEN\n",
    "    print(\"âœ… Ngrok token ayarlandÄ±!\")\n",
    "    print(\"ğŸ”— Gradio stabil bir public URL ile baÅŸlatÄ±lacak\")\n",
    "else:\n",
    "    print(\"âš ï¸ Ngrok token ayarlanmadÄ±\")\n",
    "    print(\"ğŸ“ Gradio varsayÄ±lan paylaÅŸÄ±m kullanacak (yine de Ã§alÄ±ÅŸÄ±r)\")\n",
    "    print(\"\\nğŸ’¡ Stabil URL iÃ§in ngrok.com'dan token alÄ±n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ AdÄ±m 7: Gradio ArayÃ¼zÃ¼nÃ¼ BaÅŸlat\n",
    "\n",
    "### ï¿½ï¿½ Ses restorasyonu iÃ§in hazÄ±r!\n",
    "\n",
    "**NasÄ±l kullanÄ±lÄ±r:**\n",
    "1. AÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n\n",
    "2. Ã‡Ä±kan public linke tÄ±klayÄ±n\n",
    "3. Ses dosyasÄ± yÃ¼kleyin\n",
    "4. Mod seÃ§in:\n",
    "   - **Bandwidth Extension**: YÃ¼ksek frekanslarÄ± restore et\n",
    "   - **Inpainting**: Eksik kÄ±sÄ±mlarÄ± doldur\n",
    "5. \"ğŸš€ Restore Et\" butonuna tÄ±klayÄ±n\n",
    "6. Sonucu dinleyin ve indirin!\n",
    "\n",
    "**Ayarlar:**\n",
    "- **Sampling Steps**: 25-100\n",
    "  - HÄ±zlÄ±: 25-30\n",
    "  - Dengeli: 50 â­\n",
    "  - En iyi: 75-100\n",
    "- **Otomatik Cutoff**: Ã–nerilir â­\n",
    "\n",
    "**Ä°ÅŸlem SÃ¼releri (P100 GPU):**\n",
    "- 10s ses, 50 adÄ±m: ~2-3 dakika\n",
    "- 30s ses, 50 adÄ±m: ~5-7 dakika\n",
    "- 60s ses, 50 adÄ±m: ~10-15 dakika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Gradio arayÃ¼zÃ¼nÃ¼ baÅŸlat\n",
    "print(\"ğŸš€ Gradio arayÃ¼zÃ¼ baÅŸlatÄ±lÄ±yor...\\n\")\n",
    "print(\"â±ï¸  LÃ¼tfen linkin gÃ¶rÃ¼nmesini bekleyin.\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import os\n",
    "if os.path.exists('gradio_app_kaggle.py'):\n",
    "    print(\"âœ“ Kaggle-optimize Gradio app kullanÄ±lÄ±yor\")\n",
    "    !python gradio_app_kaggle.py --ngrok\n",
    "else:\n",
    "    print(\"âš ï¸ VarsayÄ±lan Gradio app kullanÄ±lÄ±yor\")\n",
    "    !python gradio_app.py --share\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… Gradio arayÃ¼zÃ¼ baÅŸlatÄ±ldÄ±!\")\n",
    "print(\"YukarÄ±daki public linke tÄ±klayarak arayÃ¼ze eriÅŸin.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Ä°puÃ§larÄ± ve Sorun Giderme\n",
    "\n",
    "### âŒ CUDA Bellek HatasÄ±\n",
    "\n",
    "**GPU belleÄŸini temizlemek iÃ§in bu hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "print(\"ğŸ§¹ GPU belleÄŸi temizleniyor...\")\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "    \n",
    "    print(f\"\\nâœ… GPU belleÄŸi temizlendi!\")\n",
    "    print(f\"\\nBellek Durumu:\")\n",
    "    print(f\"  Toplam: {total:.2f} GB\")\n",
    "    print(f\"  KullanÄ±lan: {allocated:.2f} GB\")\n",
    "    print(f\"  BoÅŸ: {total - allocated:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¯ En Ä°yi Uygulamalar\n",
    "\n",
    "1. **KÃ¼Ã§Ã¼k baÅŸlayÄ±n**: 10-20 saniyelik ses ile test edin\n",
    "2. **VarsayÄ±lanlarÄ± kullanÄ±n**: 50 adÄ±m, otomatik cutoff\n",
    "3. **Ã‡Ä±ktÄ±larÄ± kaydedin**: Hemen indirin\n",
    "4. **Tek tek iÅŸleyin**: Bir seferde bir dosya\n",
    "\n",
    "### âŒ YaygÄ±n Sorunlar\n",
    "\n",
    "**CUDA Bellek HatasÄ±:**\n",
    "- Sampling steps'i 25-30'a dÃ¼ÅŸÃ¼rÃ¼n\n",
    "- Daha kÄ±sa ses kullanÄ±n\n",
    "- YukarÄ±daki bellek temizleme hÃ¼cresini Ã§alÄ±ÅŸtÄ±rÄ±n\n",
    "\n",
    "**Import HatalarÄ±:**\n",
    "- AdÄ±m 1'i Ã§alÄ±ÅŸtÄ±rÄ±p kernel'Ä± yeniden baÅŸlattÄ±ÄŸÄ±nÄ±zdan emin olun\n",
    "- AdÄ±m 3'Ã¼ (baÄŸÄ±mlÄ±lÄ±klar) tekrar Ã§alÄ±ÅŸtÄ±rÄ±n\n",
    "\n",
    "### ğŸ“ Dosya KonumlarÄ±\n",
    "\n",
    "- **GiriÅŸ**: Gradio Ã¼zerinden yÃ¼kleyin\n",
    "- **Ã‡Ä±ktÄ±**: `/kaggle/working/gradio_outputs/`\n",
    "- **Modeller**: `/kaggle/working/diffusion-audio-restoration-colab-Kaggle-/pretrained_models/`\n",
    "\n",
    "### ğŸ“– Kaynaklar\n",
    "\n",
    "- **Paper**: [arXiv:2501.11311](https://arxiv.org/abs/2501.11311)\n",
    "- **GitHub**: [Repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- **Models**: [HuggingFace](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‰ TeÅŸekkÃ¼rler!\n",
    "\n",
    "**AlÄ±ntÄ±:**\n",
    "```bibtex\n",
    "@article{kong2025a2sb,\n",
    "  title={A2SB: Audio-to-Audio Schrodinger Bridges},\n",
    "  author={Kong, Zhifeng and Shih, Kevin J and Nie, Weili and Vahdat, Arash and Lee, Sang-gil and Santos, Joao Felipe and Jukic, Ante and Valle, Rafael and Catanzaro, Bryan},\n",
    "  journal={arXiv preprint arXiv:2501.11311},\n",
    "  year={2025}\n",
    "}\n",
    "```\n",
    "\n",
    "### â­ Projeyi Destekle\n",
    "\n",
    "- â­ [GitHub repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)'ye yÄ±ldÄ±z verin\n",
    "- ğŸ› Hata bildirin\n",
    "- ğŸ“¢ PaylaÅŸÄ±n\n",
    "- ğŸ‘ Bu notebook'u upvote edin\n",
    "\n",
    "---\n",
    "\n",
    "**â¤ï¸ Ses restorasyonu topluluÄŸu iÃ§in yapÄ±ldÄ±**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
