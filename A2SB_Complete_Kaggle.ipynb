{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéµ A2SB: Audio Restoration - Kaggle\n",
    "\n",
    "**High-Quality Audio Restoration with NVIDIA A2SB**\n",
    "\n",
    "Restore your audio files with AI!\n",
    "\n",
    "## üöÄ Features\n",
    "- ‚úÖ 44.1kHz high-resolution audio restoration\n",
    "- ‚úÖ Bandwidth extension (high-frequency prediction)\n",
    "- ‚úÖ Audio inpainting (fill missing parts)\n",
    "- ‚úÖ User-friendly Gradio interface\n",
    "\n",
    "## üìã Requirements\n",
    "- üéØ **GPU**: P100 (16GB) recommended\n",
    "- üíæ **RAM**: Minimum 25GB\n",
    "- ‚è±Ô∏è **Time**: ~2-3 minutes for 10 seconds of audio\n",
    "\n",
    "## ‚öôÔ∏è How to Enable GPU?\n",
    "1. Click **Settings** on the right\n",
    "2. Under **Accelerator**, select **GPU P100**\n",
    "3. Click **Save**\n",
    "\n",
    "## üìö Resources\n",
    "- üìÑ [Paper](https://arxiv.org/abs/2501.11311)\n",
    "- üíª [GitHub](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- ü§ó [Models](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
    "\n",
    "---\n",
    "\n",
    "**Usage:** Run cells in order!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 1: Fix CUDA Compatibility (CRITICAL!)\n",
    "\n",
    "**‚ö†Ô∏è RUN THIS FIRST!**\n",
    "\n",
    "Kaggle has PyTorch with CUDA 11.8 but torchvision with CUDA 12.4. This causes a version mismatch error.\n",
    "\n",
    "**This cell will:**\n",
    "1. Uninstall incompatible packages\n",
    "2. Install CUDA 11.8 compatible versions\n",
    "3. Fix the version mismatch\n",
    "\n",
    "**‚è±Ô∏è Takes 2-3 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"üîß FIXING CUDA VERSION MISMATCH\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ö†Ô∏è This is CRITICAL for Kaggle compatibility!\")\n",
    "print(\"‚è±Ô∏è  This will take 2-3 minutes...\\n\")\n",
    "\n",
    "# Step 1: Uninstall incompatible packages\n",
    "print(\"üì¶ Step 1/4: Removing incompatible packages...\")\n",
    "!pip uninstall -y torch torchvision torchaudio torchmetrics transformers torchao -q\n",
    "print(\"‚úì Old packages removed\\n\")\n",
    "\n",
    "# Step 2: Install PyTorch with CUDA 11.8\n",
    "print(\"üì¶ Step 2/4: Installing PyTorch with CUDA 11.8...\")\n",
    "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 \\\n",
    "    --index-url https://download.pytorch.org/whl/cu118 -q\n",
    "print(\"‚úì PyTorch installed\\n\")\n",
    "\n",
    "# Step 3: Install compatible torchmetrics\n",
    "print(\"üì¶ Step 3/4: Installing torchmetrics...\")\n",
    "!pip install torchmetrics==1.2.0 --no-deps -q\n",
    "!pip install numpy packaging -q\n",
    "print(\"‚úì Torchmetrics installed\\n\")\n",
    "\n",
    "# Step 4: Install Lightning\n",
    "print(\"üì¶ Step 4/4: Installing Lightning...\")\n",
    "!pip install lightning==2.1.0 pytorch-lightning==2.1.0 -q\n",
    "print(\"‚úì Lightning installed\\n\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ CUDA FIX COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ö†Ô∏è IMPORTANT: You MUST restart the kernel now!\")\n",
    "print(\"\\nüëâ Go to: Session > Restart Session\")\n",
    "print(\"\\nAfter restart, continue with Step 2 (skip this cell).\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è RESTART KERNEL NOW!\n",
    "\n",
    "**After running the cell above:**\n",
    "1. Go to **Session > Restart Session**\n",
    "2. Wait for kernel to restart\n",
    "3. Continue with Step 2 below\n",
    "4. **DO NOT** run Step 1 again\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Step 2: Verify Installation (After Kernel Restart)\n",
    "\n",
    "**Run this cell to verify the CUDA fix worked.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîç VERIFYING INSTALLATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n‚úì PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úì PyTorch CUDA: {torch.version.cuda}\")\n",
    "print(f\"‚úì CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"‚úì GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    if 'P100' in torch.cuda.get_device_name(0):\n",
    "        print(\"\\nüéâ Perfect! You have a P100 GPU!\")\n",
    "    \n",
    "    if gpu_memory < 14:\n",
    "        print(f\"\\n‚ö†Ô∏è Warning: GPU only has {gpu_memory:.1f} GB memory\")\n",
    "        print(\"Recommended: Enable P100 GPU (16GB) in Settings\")\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ GPU memory is sufficient ({gpu_memory:.1f} GB)\")\n",
    "else:\n",
    "    print(\"\\n‚ùå ERROR: CUDA not available!\")\n",
    "    print(\"Please enable GPU in Settings > Accelerator > GPU P100\")\n",
    "    sys.exit(1)\n",
    "\n",
    "if torch.version.cuda == \"11.8\":\n",
    "    print(f\"\\n‚úÖ CUDA version is correct: {torch.version.cuda}\")\n",
    "    print(\"‚úÖ No version mismatch - Ready to proceed!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Warning: PyTorch CUDA version is {torch.version.cuda}\")\n",
    "    print(\"Expected: 11.8\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ VERIFICATION COMPLETE!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 3: Install Dependencies\n",
    "\n",
    "**Install remaining packages needed for audio restoration.**\n",
    "\n",
    "**‚è±Ô∏è Takes 3-5 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"üì¶ Installing dependencies...\\n\")\n",
    "\n",
    "# Audio processing libraries\n",
    "print(\"üì• Installing audio processing libraries...\")\n",
    "!pip install librosa soundfile scipy einops -q\n",
    "print(\"‚úì Audio libraries installed\\n\")\n",
    "\n",
    "# Configuration tools\n",
    "print(\"üì• Installing configuration tools...\")\n",
    "!pip install jsonargparse[signatures] pyyaml -q\n",
    "print(\"‚úì Configuration tools installed\\n\")\n",
    "\n",
    "# Gradio and utilities\n",
    "print(\"üì• Installing Gradio and utilities...\")\n",
    "!pip install 'huggingface_hub>=0.19.0,<1.0' -q\n",
    "!pip install gradio==4.44.0 -q\n",
    "!pip install nest-asyncio tqdm rotary-embedding-torch pyngrok -q\n",
    "print(\"‚úì Gradio installed\\n\")\n",
    "\n",
    "# Optional: SSR Eval\n",
    "!pip install ssr-eval -q 2>/dev/null || echo \"‚ö†Ô∏è SSR Eval skipped (optional)\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ALL DEPENDENCIES INSTALLED!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Verification\n",
    "import torch\n",
    "import lightning\n",
    "import gradio as gr\n",
    "import librosa\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(f\"\\n‚úì PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úì Lightning: {lightning.__version__}\")\n",
    "print(f\"‚úì Gradio: {gr.__version__}\")\n",
    "print(f\"‚úì Librosa: {librosa.__version__}\")\n",
    "print(\"\\nüéâ Ready to proceed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ÔøΩÔøΩÔøΩ Step 4: Clone Repository\n",
    "\n",
    "**Download the audio restoration code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"üì• Cloning repository...\\n\")\n",
    "\n",
    "os.chdir('/kaggle/working')\n",
    "!rm -rf diffusion-audio-restoration-colab-Kaggle-\n",
    "!git clone https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git\n",
    "os.chdir('diffusion-audio-restoration-colab-Kaggle-')\n",
    "\n",
    "print(f\"\\n‚úÖ Repository cloned!\")\n",
    "print(f\"‚úì Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ó Step 5: Download Models\n",
    "\n",
    "**Download two model checkpoints from Hugging Face:**\n",
    "- One-split (0.0-1.0): ~1.5GB\n",
    "- Two-split (0.5-1.0): ~1.5GB\n",
    "\n",
    "**Total: ~3GB. Takes 5-10 minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "print(\"ü§ó Downloading models from Hugging Face...\")\n",
    "print(\"‚è±Ô∏è  This will take 5-10 minutes...\\n\")\n",
    "\n",
    "model_dir = './pretrained_models'\n",
    "\n",
    "try:\n",
    "    snapshot_download(\n",
    "        repo_id='nvidia/audio_to_audio_schrodinger_bridge',\n",
    "        local_dir=model_dir,\n",
    "        local_dir_use_symlinks=False\n",
    "    )\n",
    "    print(f\"\\n‚úÖ Models downloaded: {model_dir}\")\n",
    "    print(f\"\\nüìÇ Model files:\")\n",
    "    !ls -lh {model_dir}\n",
    "    print(\"\\n‚úÖ Model download complete!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Model download error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Check your internet connection\")\n",
    "    print(\"2. Verify Hugging Face is accessible\")\n",
    "    print(\"3. Try running this cell again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Step 6: Ngrok Token (Optional but Recommended)\n",
    "\n",
    "**Ngrok provides a stable public URL for your Gradio interface.**\n",
    "\n",
    "### How to get Ngrok token:\n",
    "1. Go to [ngrok.com](https://ngrok.com/)\n",
    "2. Sign up for free account\n",
    "3. Go to [Dashboard](https://dashboard.ngrok.com/get-started/your-authtoken)\n",
    "4. Copy your authtoken\n",
    "5. Paste it below\n",
    "\n",
    "**Note:** Without ngrok token, Gradio will use its default sharing (also works fine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Paste your Ngrok token here (optional)\n",
    "NGROK_TOKEN = \"\"  # Example: \"2abc123def456ghi789jkl\"\n",
    "\n",
    "if NGROK_TOKEN:\n",
    "    os.environ['NGROK_TOKEN'] = NGROK_TOKEN\n",
    "    print(\"‚úÖ Ngrok token set!\")\n",
    "    print(\"üîó Gradio will launch with a stable public URL\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Ngrok token not set\")\n",
    "    print(\"üìù Gradio will use default sharing (still works)\")\n",
    "    print(\"\\nüí° For stable URL, get token from ngrok.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Step 7: Launch Gradio Interface\n",
    "\n",
    "### üöÄ Ready to restore audio!\n",
    "\n",
    "**How to use:**\n",
    "1. Run the cell below\n",
    "2. Click the public link\n",
    "3. Upload audio file\n",
    "4. Choose mode:\n",
    "   - **Bandwidth Extension**: Restore high frequencies\n",
    "   - **Inpainting**: Fill missing parts\n",
    "5. Click \"üöÄ Restore\"\n",
    "6. Listen and download the result!\n",
    "\n",
    "**Settings:**\n",
    "- **Sampling Steps**: 25-100\n",
    "  - Fast: 25-30\n",
    "  - Balanced: 50 ‚≠ê\n",
    "  - Best: 75-100\n",
    "- **Auto Cutoff**: Recommended ‚≠ê\n",
    "\n",
    "**Processing Times (P100 GPU):**\n",
    "- 10s audio, 50 steps: ~2-3 minutes\n",
    "- 30s audio, 50 steps: ~5-7 minutes\n",
    "- 60s audio, 50 steps: ~10-15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Launch Gradio interface\n",
    "print(\"üöÄ Launching Gradio interface...\\n\")\n",
    "print(\"‚è±Ô∏è  Please wait for the link to appear.\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import os\n",
    "if os.path.exists('gradio_app_kaggle.py'):\n",
    "    print(\"‚úì Using Kaggle-optimized Gradio app\")\n",
    "    !python gradio_app_kaggle.py --ngrok\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Using default Gradio app\")\n",
    "    !python gradio_app.py --share\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Gradio interface launched!\")\n",
    "print(\"Click the public link above to access the interface.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Tips and Troubleshooting\n",
    "\n",
    "### ‚ùå CUDA Out of Memory\n",
    "\n",
    "**Run this cell to clear GPU memory:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "print(\"üßπ Clearing GPU memory...\")\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
    "    \n",
    "    print(f\"\\n‚úÖ GPU memory cleared!\")\n",
    "    print(f\"\\nMemory Status:\")\n",
    "    print(f\"  Total: {total:.2f} GB\")\n",
    "    print(f\"  Allocated: {allocated:.2f} GB\")\n",
    "    print(f\"  Free: {total - allocated:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Best Practices\n",
    "\n",
    "1. **Start small**: Test with 10-20 second audio\n",
    "2. **Use defaults**: 50 steps, auto cutoff\n",
    "3. **Save outputs**: Download immediately\n",
    "4. **Process one at a time**: One file at a time\n",
    "\n",
    "### ‚ùå Common Issues\n",
    "\n",
    "**CUDA Out of Memory:**\n",
    "- Reduce sampling steps to 25-30\n",
    "- Use shorter audio\n",
    "- Run the memory clearing cell above\n",
    "\n",
    "**Import Errors:**\n",
    "- Make sure you ran Step 1 and restarted kernel\n",
    "- Re-run Step 3 (dependencies)\n",
    "\n",
    "### üìÅ File Locations\n",
    "\n",
    "- **Input**: Upload via Gradio\n",
    "- **Output**: `/kaggle/working/gradio_outputs/`\n",
    "- **Models**: `/kaggle/working/diffusion-audio-restoration-colab-Kaggle-/pretrained_models/`\n",
    "\n",
    "### üìñ Resources\n",
    "\n",
    "- **Paper**: [arXiv:2501.11311](https://arxiv.org/abs/2501.11311)\n",
    "- **GitHub**: [Repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- **Models**: [HuggingFace](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Thank You!\n",
    "\n",
    "**Citation:**\n",
    "```bibtex\n",
    "@article{kong2025a2sb,\n",
    "  title={A2SB: Audio-to-Audio Schrodinger Bridges},\n",
    "  author={Kong, Zhifeng and Shih, Kevin J and Nie, Weili and Vahdat, Arash and Lee, Sang-gil and Santos, Joao Felipe and Jukic, Ante and Valle, Rafael and Catanzaro, Bryan},\n",
    "  journal={arXiv preprint arXiv:2501.11311},\n",
    "  year={2025}\n",
    "}\n",
    "```\n",
    "\n",
    "### ‚≠ê Support This Project\n",
    "\n",
    "- ‚≠ê Star the [GitHub repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- üêõ Report bugs\n",
    "- üì¢ Share with others\n",
    "- üëç Upvote this notebook\n",
    "\n",
    "---\n",
    "\n",
    "**‚ù§Ô∏è Made for the audio restoration community**"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
