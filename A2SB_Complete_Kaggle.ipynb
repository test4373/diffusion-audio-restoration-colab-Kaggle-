{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéµ A2SB: Audio-to-Audio Schr√∂dinger Bridge - Kaggle Edition\n",
    "\n",
    "**High-Quality Audio Restoration with NVIDIA A2SB**\n",
    "\n",
    "This notebook includes **everything** you need: model download, setup, and Gradio web interface!\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT: GPU Required\n",
    "\n",
    "**This notebook requires Kaggle GPU acceleration!**\n",
    "\n",
    "### GPU Requirements:\n",
    "- üéØ **GPU Memory**: Requires 15GB+ GPU VRAM (P100 or T4 x2)\n",
    "- ‚è±Ô∏è **Processing Time**: Long audio files need extended runtime\n",
    "- üíæ **RAM**: Minimum 25GB system RAM recommended\n",
    "- üöÄ **Performance**: Better GPUs for faster processing\n",
    "\n",
    "### How to Enable GPU on Kaggle:\n",
    "1. Click **Settings** (right sidebar)\n",
    "2. Under **Accelerator**, select **GPU P100** or **GPU T4 x2**\n",
    "3. Click **Save**\n",
    "\n",
    "### Kaggle Advantages:\n",
    "- ‚úÖ Free GPU access (30 hours/week)\n",
    "- ‚úÖ P100 GPU with 16GB VRAM\n",
    "- ‚úÖ 30GB RAM\n",
    "- ‚úÖ Persistent storage\n",
    "- ‚úÖ No subscription required\n",
    "\n",
    "---\n",
    "\n",
    "## üåü Features\n",
    "- ‚úÖ 44.1kHz high-resolution music restoration\n",
    "- ‚úÖ Bandwidth extension (high-frequency prediction)\n",
    "- ‚úÖ Audio inpainting (reconstruct missing segments)\n",
    "- ‚úÖ Support for long audio files (hours)\n",
    "- ‚úÖ End-to-end, no vocoder required\n",
    "- ‚úÖ **Gradio Web Interface** - User-friendly UI\n",
    "\n",
    "## üìö Resources\n",
    "- üìÑ [Paper](https://arxiv.org/abs/2501.11311)\n",
    "- üíª [GitHub Repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- üé¨ [Original NVIDIA Demo](https://research.nvidia.com/labs/adlr/A2SB/)\n",
    "- ü§ó [Models](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
    "\n",
    "---\n",
    "\n",
    "**Usage:** Run cells in order. The last cell will launch the Gradio interface!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 0: Check Your Kaggle Environment\n",
    "\n",
    "**Run this cell to verify your GPU and system status.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-01T00:00:00.000000Z",
     "iopub.status.busy": "2024-01-01T00:00:00.000000Z",
     "iopub.status.idle": "2024-01-01T00:00:00.000000Z",
     "shell.execute_reply": "2024-01-01T00:00:00.000000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîç CHECKING KAGGLE ENVIRONMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check GPU\n",
    "try:\n",
    "    gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], text=True)\n",
    "    gpu_name, gpu_memory = gpu_info.strip().split(', ')\n",
    "    gpu_memory_gb = int(gpu_memory.split()[0]) / 1024\n",
    "    \n",
    "    print(f\"\\n‚úì GPU Detected: {gpu_name}\")\n",
    "    print(f\"‚úì GPU Memory: {gpu_memory_gb:.1f} GB\")\n",
    "    \n",
    "    # Check if sufficient\n",
    "    if gpu_memory_gb < 14:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚ö†Ô∏è  WARNING: INSUFFICIENT GPU MEMORY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Your GPU has {gpu_memory_gb:.1f} GB memory.\")\n",
    "        print(\"This notebook requires at least 15GB GPU memory.\")\n",
    "        print(\"\\nüî¥ RECOMMENDATION: Enable P100 GPU in Kaggle Settings!\")\n",
    "        print(\"\\nYou may experience:\")\n",
    "        print(\"  - Out of Memory errors\")\n",
    "        print(\"  - Failed inference\")\n",
    "        print(\"  - Slow processing\")\n",
    "        print(\"\\nüëâ Enable GPU: Settings > Accelerator > GPU P100\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"\\n‚úÖ GPU memory is sufficient!\")\n",
    "        if 'P100' in gpu_name:\n",
    "            print(\"üéâ You have a P100 GPU! Perfect for this notebook!\")\n",
    "        elif 'T4' in gpu_name:\n",
    "            print(\"‚úì T4 GPU detected - Good for this notebook\")\n",
    "        elif 'V100' in gpu_name:\n",
    "            print(\"üéâ You have a V100 GPU! Excellent performance!\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(\"\\n‚ùå ERROR: No GPU detected!\")\n",
    "    print(\"\\nPlease enable GPU:\")\n",
    "    print(\"1. Click 'Settings' in the right sidebar\")\n",
    "    print(\"2. Under 'Accelerator', select 'GPU P100' or 'GPU T4 x2'\")\n",
    "    print(\"3. Click 'Save'\")\n",
    "    print(\"4. Restart the notebook\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Check RAM\n",
    "try:\n",
    "    with open('/proc/meminfo', 'r') as f:\n",
    "        meminfo = f.read()\n",
    "    mem_total = int([line for line in meminfo.split('\\n') if 'MemTotal' in line][0].split()[1]) / 1024 / 1024\n",
    "    print(f\"\\n‚úì System RAM: {mem_total:.1f} GB\")\n",
    "    \n",
    "    if mem_total < 20:\n",
    "        print(\"‚ö†Ô∏è  Low RAM detected. This may cause issues with large audio files.\")\n",
    "    else:\n",
    "        print(\"‚úÖ RAM is sufficient!\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Check Kaggle working directory\n",
    "print(f\"\\n‚úì Working Directory: {os.getcwd()}\")\n",
    "print(f\"‚úì Kaggle Input: /kaggle/input/\")\n",
    "print(f\"‚úì Kaggle Working: /kaggle/working/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Environment check complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nKaggle provides free GPU access with:\")\n",
    "print(\"  ‚Ä¢ 30 hours GPU time per week\")\n",
    "print(\"  ‚Ä¢ P100 GPU (16GB VRAM)\")\n",
    "print(\"  ‚Ä¢ 30GB RAM\")\n",
    "print(\"  ‚Ä¢ 73GB disk space\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Setup and Dependencies\n",
    "\n",
    "**This will take 5-10 minutes. Please be patient!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Clone the optimized repository\n",
    "print(\"üì• Cloning repository...\\n\")\n",
    "\n",
    "# Change to /kaggle/working directory (writable)\n",
    "import os\n",
    "os.chdir('/kaggle/working')\n",
    "\n",
    "# Remove if exists\n",
    "!rm -rf diffusion-audio-restoration-colab-Kaggle-\n",
    "\n",
    "# Clone repository\n",
    "!git clone https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git\n",
    "os.chdir('diffusion-audio-restoration-colab-Kaggle-')\n",
    "\n",
    "print(f\"\\n‚úÖ Repository cloned successfully!\")\n",
    "print(f\"‚úì Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Install required libraries - FIXED for torchaudio compatibility\n",
    "print(\"üì¶ Installing dependencies...\\n\")\n",
    "print(\"‚è±Ô∏è  This will take 5-10 minutes. Please wait...\\n\")\n",
    "\n",
    "# Step 1: Fix torchaudio compatibility issue\n",
    "print(\"üîß Fixing torchaudio compatibility...\")\n",
    "!pip uninstall -y torchaudio 2>/dev/null || true\n",
    "import torch\n",
    "torch_version = torch.__version__.split('+')[0]\n",
    "print(f\"‚úì Detected PyTorch version: {torch_version}\")\n",
    "\n",
    "# Install matching torchaudio\n",
    "if torch_version.startswith('2.6'):\n",
    "    !pip install -q torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "elif torch_version.startswith('2.5'):\n",
    "    !pip install -q torchaudio==2.5.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "elif torch_version.startswith('2.4'):\n",
    "    !pip install -q torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118\n",
    "else:\n",
    "    !pip install -q torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Step 2: Install other packages\n",
    "print(\"\\nüì• Installing required packages...\")\n",
    "!pip install -q lightning \"pytorch-lightning>=2.0.0\"\n",
    "!pip install -q librosa soundfile\n",
    "!pip install -q einops gradio \"jsonargparse[signatures]>=4.0.0\"\n",
    "!pip install -q rotary-embedding-torch\n",
    "!pip install -q pyyaml tqdm\n",
    "!pip install -q nest-asyncio\n",
    "!pip install -q pyngrok  # Ngrok for Kaggle\n",
    "\n",
    "# Optional: SSR Eval\n",
    "print(\"üì• Installing optional packages...\")\n",
    "!pip install -q ssr-eval 2>/dev/null || echo \"‚ö†Ô∏è SSR Eval installation skipped (optional)\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Installation complete! Verifying...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "import lightning\n",
    "import gradio as gr\n",
    "import nest_asyncio\n",
    "\n",
    "# Fix event loop issue\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(f\"\\n‚úì PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úì Lightning: {lightning.__version__}\")\n",
    "print(f\"‚úì Gradio: {gr.__version__}\")\n",
    "print(f\"‚úì CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úì GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# Check torchvision\n",
    "try:\n",
    "    import torchvision\n",
    "    print(f\"‚úì TorchVision: {torchvision.__version__}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è TorchVision: {str(e)[:50]}... (non-critical)\")\n",
    "\n",
    "# SSR Eval check\n",
    "try:\n",
    "    import ssr_eval\n",
    "    print(f\"‚úì SSR Eval: Installed\")\n",
    "except ImportError:\n",
    "    print(f\"‚ö†Ô∏è SSR Eval: Not installed (optional)\")\n",
    "\n",
    "print(\"\\nüéâ All libraries successfully installed!\")\n",
    "print(\"‚úÖ Using Kaggle's pre-installed PyTorch (compatible with system)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• 2. Download Model Files\n",
    "\n",
    "We'll download two model checkpoints:\n",
    "- **One-split (0.0-1.0)**: Full time range (~1.5GB)\n",
    "- **Two-split (0.5-1.0)**: Second time range (~1.5GB)\n",
    "\n",
    "**Total download: ~3GB. This will take 5-10 minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create checkpoint directory\n",
    "!mkdir -p ckpt\n",
    "print(\"‚úì Checkpoint directory created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"üì• Downloading model checkpoints...\\n\")\n",
    "print(\"‚è±Ô∏è  This will take 5-10 minutes depending on your connection.\\n\")\n",
    "\n",
    "# Model files\n",
    "models = {\n",
    "    'onesplit': {\n",
    "        'path': 'ckpt/A2SB_onesplit_0.0_1.0_release.ckpt',\n",
    "        'url': 'https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge/resolve/main/ckpt/A2SB_onesplit_0.0_1.0_release.ckpt'\n",
    "    },\n",
    "    'twosplit': {\n",
    "        'path': 'ckpt/A2SB_twosplit_0.5_1.0_release.ckpt',\n",
    "        'url': 'https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge/resolve/main/ckpt/A2SB_twosplit_0.5_1.0_release.ckpt'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check and download each model\n",
    "for name, info in models.items():\n",
    "    if os.path.exists(info['path']):\n",
    "        size_mb = os.path.getsize(info['path']) / (1024 * 1024)\n",
    "        print(f\"‚úì {name} model already exists ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"‚¨áÔ∏è  Downloading {name} model (~1.5GB)...\")\n",
    "        !wget -q --show-progress -O {info['path']} {info['url']}\n",
    "        if os.path.exists(info['path']):\n",
    "            size_mb = os.path.getsize(info['path']) / (1024 * 1024)\n",
    "            print(f\"‚úÖ {name} model downloaded ({size_mb:.2f} MB)\")\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to download {name} model!\")\n",
    "            print(f\"Please check your internet connection and try again.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ Model download complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è 3. Configuration\n",
    "\n",
    "Update the configuration file with the correct model paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "print(\"‚öôÔ∏è  Updating configuration...\\n\")\n",
    "\n",
    "# Update config file\n",
    "config_path = 'configs/ensemble_2split_sampling.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['model']['pretrained_checkpoints'] = [\n",
    "    'ckpt/A2SB_onesplit_0.0_1.0_release.ckpt',\n",
    "    'ckpt/A2SB_twosplit_0.5_1.0_release.ckpt'\n",
    "]\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"‚úÖ Configuration updated successfully!\")\n",
    "print(f\"\\nModel paths:\")\n",
    "for i, path in enumerate(config['model']['pretrained_checkpoints'], 1):\n",
    "    print(f\"  {i}. {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® 4. Launch Gradio Web Interface\n",
    "\n",
    "### üöÄ Ready to restore audio!\n",
    "\n",
    "**Features:**\n",
    "- üì§ Drag-and-drop file upload\n",
    "- üé§ Microphone recording\n",
    "- ‚öôÔ∏è Advanced settings (sampling steps, cutoff frequency)\n",
    "- üìä Real-time progress tracking\n",
    "- üîä Instant playback and comparison\n",
    "- üìà Spectral analysis visualization\n",
    "\n",
    "**How to use:**\n",
    "1. **Run the cell below** - Wait for the Gradio link to appear\n",
    "2. **Click the public link** (usually ends with `.gradio.live`)\n",
    "3. **Upload audio** or record from microphone\n",
    "4. **Choose mode:**\n",
    "   - **Bandwidth Extension**: Restore high frequencies (for low-quality MP3s)\n",
    "   - **Inpainting**: Fill in missing audio segments\n",
    "5. **Adjust settings** (optional):\n",
    "   - Sampling Steps: 25-100 (higher = better quality, slower)\n",
    "   - Auto Cutoff: Automatically detect cutoff frequency\n",
    "   - Inpainting Length: 0.1-1.0 seconds\n",
    "6. **Click \"üöÄ Restore\"** and wait for processing\n",
    "7. **Listen & Download** the restored audio\n",
    "\n",
    "**Tips:**\n",
    "- Start with default settings (50 steps, auto cutoff)\n",
    "- For faster results: 25-30 steps\n",
    "- For best quality: 75-100 steps\n",
    "- Processing time: ~2-3 minutes per 10 seconds of audio (on P100)\n",
    "\n",
    "**‚ö†Ô∏è Important:**\n",
    "- Keep this notebook tab open during processing\n",
    "- Don't close the Kaggle session\n",
    "- If you get \"Out of Memory\" error, reduce sampling steps or audio length\n",
    "- Gradio will create a public URL that expires after 72 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Launch Gradio interface with public URL\n",
    "print(\"üöÄ Launching Gradio interface...\\n\")\n",
    "print(\"‚è±Ô∏è  Please wait for the link to appear below.\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Kaggle i√ßin √∂zel gradio_app kullan (ngrok ile)\n",
    "import os\n",
    "if os.path.exists('gradio_app_kaggle.py'):\n",
    "    print(\"‚úì Using Kaggle-optimized Gradio app with ngrok\")\n",
    "    !python gradio_app_kaggle.py --ngrok\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Using default Gradio app\")\n",
    "    !python gradio_app.py --share\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Gradio interface launched!\")\n",
    "print(\"Click the public link above to access the web interface.\")\n",
    "print(\"The link will be valid for 72 hours.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö 5. Tips and Troubleshooting\n",
    "\n",
    "### ‚ö° Performance Optimization\n",
    "\n",
    "**GPU Requirements:**\n",
    "- ‚úÖ **Kaggle P100**: 16GB VRAM (Recommended)\n",
    "- ‚úÖ **Kaggle T4 x2**: 2x 16GB VRAM (Excellent)\n",
    "- ‚ö†Ô∏è **Kaggle T4**: 16GB VRAM (May work)\n",
    "\n",
    "**Processing Times (on P100 GPU):**\n",
    "- 10 seconds audio, 50 steps: ~2-3 minutes\n",
    "- 30 seconds audio, 50 steps: ~5-7 minutes\n",
    "- 60 seconds audio, 50 steps: ~10-15 minutes\n",
    "\n",
    "### üéØ Quality Settings\n",
    "\n",
    "**Sampling Steps:**\n",
    "- **25-30:** Fast (good quality)\n",
    "- **50-75:** Balanced (excellent quality) ‚≠ê Recommended\n",
    "- **75-100:** Best (outstanding quality)\n",
    "\n",
    "**Cutoff Frequency (Bandwidth Extension):**\n",
    "- **Auto-detect**: Usually best ‚≠ê Recommended\n",
    "- **Manual adjustment:**\n",
    "  - Low-quality MP3: 2000-4000 Hz\n",
    "  - Medium quality: 4000-8000 Hz\n",
    "  - High quality: 8000+ Hz\n",
    "\n",
    "**Inpainting Length:**\n",
    "- 0.1-0.3s: Small gaps or clicks\n",
    "- 0.3-0.5s: Medium gaps\n",
    "- 0.5-1.0s: Large missing segments\n",
    "\n",
    "### üîß Troubleshooting\n",
    "\n",
    "#### ‚ùå CUDA Out of Memory Error\n",
    "\n",
    "**Solutions:**\n",
    "1. **Reduce sampling steps** to 25-30\n",
    "2. **Split audio** into shorter segments (10-20 seconds)\n",
    "3. **Restart kernel**: Kernel > Restart Kernel\n",
    "4. **Clear GPU memory**: Run the cell below\n",
    "5. **Enable P100 GPU** in Kaggle settings\n",
    "\n",
    "```python\n",
    "# Clear GPU memory\n",
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"‚úÖ GPU memory cleared\")\n",
    "```\n",
    "\n",
    "#### ‚ùå Import Errors\n",
    "\n",
    "**Solution:** Re-run the installation cell (Section 1, second cell)\n",
    "- The notebook uses Kaggle's pre-installed PyTorch\n",
    "- Only installs missing packages to avoid conflicts\n",
    "\n",
    "#### ‚ùå Model Not Found Error\n",
    "\n",
    "**Solutions:**\n",
    "1. Re-run the model download cells (Section 2)\n",
    "2. Check your internet connection\n",
    "3. Verify files exist:\n",
    "```python\n",
    "!ls -lh ckpt/\n",
    "```\n",
    "\n",
    "#### ‚ùå Gradio Interface Not Loading\n",
    "\n",
    "**Solutions:**\n",
    "1. Wait 30-60 seconds for the link to appear\n",
    "2. Check if the cell is still running\n",
    "3. Restart kernel and run all cells again\n",
    "4. Make sure you're using `--share` flag for public URL\n",
    "\n",
    "#### ‚ùå Audio Format Error\n",
    "\n",
    "**Solution:** Convert to WAV format\n",
    "```python\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Convert any audio to WAV\n",
    "y, sr = librosa.load('input.mp3', sr=44100)\n",
    "sf.write('input.wav', y, sr)\n",
    "```\n",
    "\n",
    "#### ‚ö†Ô∏è Session Timeout\n",
    "\n",
    "**Solutions:**\n",
    "1. Kaggle provides 12 hours of continuous runtime\n",
    "2. Keep the tab active\n",
    "3. Process shorter audio files\n",
    "4. Save intermediate results to `/kaggle/working/`\n",
    "\n",
    "### üí° Best Practices\n",
    "\n",
    "1. **Start small**: Test with 10-20 second clips first\n",
    "2. **Use defaults**: 50 steps, auto cutoff works well\n",
    "3. **Monitor GPU**: Check `nvidia-smi` if issues occur\n",
    "4. **Save outputs**: Download restored audio immediately\n",
    "5. **Batch processing**: Process multiple files one at a time\n",
    "6. **Use Kaggle Datasets**: Upload your audio files as a Kaggle dataset for easier access\n",
    "\n",
    "### üìÅ Kaggle File System\n",
    "\n",
    "**Important directories:**\n",
    "- `/kaggle/input/`: Read-only input data (datasets)\n",
    "- `/kaggle/working/`: Writable directory (your work)\n",
    "- `/kaggle/temp/`: Temporary files\n",
    "\n",
    "**Upload audio files:**\n",
    "1. Create a Kaggle dataset with your audio files\n",
    "2. Add the dataset to your notebook\n",
    "3. Access files from `/kaggle/input/your-dataset-name/`\n",
    "\n",
    "**Download results:**\n",
    "- Restored audio files are saved in `/kaggle/working/`\n",
    "- Click the \"Output\" tab to download files\n",
    "- Or use the Gradio interface to download directly\n",
    "\n",
    "### üìñ License and Usage\n",
    "\n",
    "- **Model:** NVIDIA OneWay NonCommercial License\n",
    "- **Code:** NVIDIA Source Code License - Non Commercial\n",
    "- **Commercial Use:** Contact NVIDIA for licensing\n",
    "- **Research Use:** Free for academic and research purposes\n",
    "\n",
    "### üîó Additional Resources\n",
    "\n",
    "- **Paper:** [arXiv:2501.11311](https://arxiv.org/abs/2501.11311)\n",
    "- **GitHub:** [test4373/diffusion-audio-restoration](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- **Original NVIDIA Repo:** [NVIDIA/diffusion-audio-restoration](https://github.com/NVIDIA/diffusion-audio-restoration)\n",
    "- **Demo:** [NVIDIA Research](https://research.nvidia.com/labs/adlr/A2SB/)\n",
    "- **Models:** [HuggingFace](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
    "\n",
    "### üìß Support\n",
    "\n",
    "- **Issues:** [GitHub Issues](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-/issues)\n",
    "- **Original NVIDIA Issues:** [NVIDIA GitHub](https://github.com/NVIDIA/diffusion-audio-restoration/issues)\n",
    "- **Kaggle Community:** [Kaggle Forums](https://www.kaggle.com/discussions)\n",
    "\n",
    "---\n",
    "\n",
    "### üéâ Thank You!\n",
    "\n",
    "Thank you for using this notebook on Kaggle!\n",
    "\n",
    "**Citation:**\n",
    "```bibtex\n",
    "@article{kong2025a2sb,\n",
    "  title={A2SB: Audio-to-Audio Schrodinger Bridges},\n",
    "  author={Kong, Zhifeng and Shih, Kevin J and Nie, Weili and Vahdat, Arash and Lee, Sang-gil and Santos, Joao Felipe and Jukic, Ante and Valle, Rafael and Catanzaro, Bryan},\n",
    "  journal={arXiv preprint arXiv:2501.11311},\n",
    "  year={2025}\n",
    "}\n",
    "```\n",
    "\n",
    "### ‚≠ê Support This Project\n",
    "\n",
    "If you find this project useful:\n",
    "- ‚≠ê Star the [GitHub repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- üêõ Report bugs or suggest features\n",
    "- üì¢ Share with others who might benefit\n",
    "- üëç Upvote this Kaggle notebook\n",
    "\n",
    "---\n",
    "\n",
    "**Made with ‚ù§Ô∏è for the audio restoration community**\n",
    "\n",
    "**Optimized for Kaggle with GPU memory management and user-friendly interface**\n",
    "\n",
    "### üÜì Why Kaggle?\n",
    "\n",
    "Kaggle offers several advantages:\n",
    "- **Free GPU access**: 30 hours per week\n",
    "- **Powerful hardware**: P100 GPU with 16GB VRAM\n",
    "- **Generous resources**: 30GB RAM, 73GB disk\n",
    "- **Persistent storage**: Save your work and models\n",
    "- **Community**: Share and collaborate with others\n",
    "- **No subscription**: Completely free!\n",
    "\n",
    "Perfect for audio restoration projects! üéµ"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
