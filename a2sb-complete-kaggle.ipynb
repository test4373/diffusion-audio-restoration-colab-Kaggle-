{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üéµ A2SB: Audio-to-Audio Schr√∂dinger Bridge - Kaggle Edition\n\n**High-Quality Audio Restoration with NVIDIA A2SB**\n\nThis notebook includes **everything** you need: model download, setup, and Gradio web interface!\n\n## ‚ö†Ô∏è IMPORTANT: GPU Required\n\n**This notebook requires Kaggle GPU acceleration!**\n\n### GPU Requirements:\n- üéØ **GPU Memory**: Requires 15GB+ GPU VRAM (P100 or T4 x2)\n- ‚è±Ô∏è **Processing Time**: Long audio files need extended runtime\n- üíæ **RAM**: Minimum 25GB system RAM recommended\n- üöÄ **Performance**: Better GPUs for faster processing\n\n### How to Enable GPU on Kaggle:\n1. Click **Settings** (right sidebar)\n2. Under **Accelerator**, select **GPU P100** or **GPU T4 x2**\n3. Click **Save**\n\n### Kaggle Advantages:\n- ‚úÖ Free GPU access (30 hours/week)\n- ‚úÖ P100 GPU with 16GB VRAM\n- ‚úÖ 30GB RAM\n- ‚úÖ Persistent storage\n- ‚úÖ No subscription required\n\n---\n\n## üåü Features\n- ‚úÖ 44.1kHz high-resolution music restoration\n- ‚úÖ Bandwidth extension (high-frequency prediction)\n- ‚úÖ Audio inpainting (reconstruct missing segments)\n- ‚úÖ Support for long audio files (hours)\n- ‚úÖ End-to-end, no vocoder required\n- ‚úÖ **Gradio Web Interface** - User-friendly UI\n\n## üìö Resources\n- üìÑ [Paper](https://arxiv.org/abs/2501.11311)\n- üíª [GitHub Repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n- üé¨ [Original NVIDIA Demo](https://research.nvidia.com/labs/adlr/A2SB/)\n- ü§ó [Models](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n\n---\n\n**Usage:** Run cells in order. The last cell will launch the Gradio interface!","metadata":{}},{"cell_type":"markdown","source":"## üì¶ 1. Setup and Dependencies\n\n**This will take 5-10 minutes. Please be patient!**","metadata":{}},{"cell_type":"code","source":"# Clone the optimized repository\nprint(\"üì• Cloning repository...\\n\")\n\n# Change to /kaggle/working directory (writable)\nimport os\nos.chdir('/kaggle/working')\n\n# Remove if exists\n!rm -rf diffusion-audio-restoration-colab-Kaggle-\n\n# Clone repository\n!git clone https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git\nos.chdir('diffusion-audio-restoration-colab-Kaggle-')\n\nprint(f\"\\n‚úÖ Repository cloned successfully!\")\nprint(f\"‚úì Current directory: {os.getcwd()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Shortened Combined Installation & Fix Script - Fixed NumPy Downgrade & Restart Note\n# Key Fix: Force uninstall/reinstall NumPy 1.x to avoid extension conflicts.\n# Run installs, then RESTART RUNTIME before verification/app launch.\n\nprint(\"üì¶ Shortened Installation & Fixes - Starting...\")\nprint(\"‚è±Ô∏è  5-10 minutes...\\n\")\n\nimport torch\ntorch_version = torch.__version__.split('+')[0]\ncuda_version = torch.version.cuda\nindex_url = \"https://download.pytorch.org/whl/cu124\" if '12.4' in cuda_version else \"https://download.pytorch.org/whl/cu118\"\n\nprint(f\"üîß PyTorch {torch_version}, CUDA {cuda_version} - Using {index_url.split('/')[-1]} wheels\")\n\n# Core audio/vision fixes\n!pip uninstall -y torchaudio torchvision transformers huggingface-hub torchmetrics 2>/dev/null || true\nif torch_version.startswith('2.6'):\n    !pip install -q torchaudio==2.6.0+cu124 torchvision==0.21.0+cu124 --index-url {index_url}\nelif torch_version.startswith('2.5'):\n    !pip install -q torchaudio==2.5.0+cu124 torchvision==0.20.0+cu124 --index-url {index_url}\nelif torch_version.startswith('2.4'):\n    !pip install -q torchaudio==2.4.0+cu124 torchvision==0.19.0+cu124 --index-url {index_url}\nelse:\n    !pip install -q torchaudio torchvision --index-url {index_url}\n\n# Transformers & metrics\n!pip install -q \"huggingface-hub<1.0,>=0.24.0\" \"transformers>=4.44.0,<4.45.0\" \"torchmetrics>=1.4.0,<1.5.0\"\n\n# Main packages\n!pip install -q \"lightning>=2.5.0\" librosa soundfile einops gradio \"jsonargparse[signatures]>=4.0.0\" rotary-embedding-torch pyyaml tqdm nest-asyncio\n\n# RAPIDS alignment (full upgrade to 25.6 to reduce conflicts)\n!pip install -q --upgrade \"rmm-cu12==25.6.*\" \"libraft-cu12==25.6.*\" \"pylibraft-cu12==25.6.*\" \"libcugraph-cu12==25.6.*\" \"pylibcugraph-cu12==25.6.*\" \"cugraph-cu12==25.6.*\" \"cuml-cu12==25.6.*\" \"cuvs-cu12==25.6.*\" \"cudf-cu12==25.6.*\" \"pylibcudf-cu12==25.6.*\"\n\n# Dataset/Gradio fixes\n!pip install -q --upgrade \"pyarrow>=21.0.0\" \"pydantic>=2.0,<2.12\"\n\n# NumPy & scikit-learn (FORCE downgrade NumPy 1.x for extension compatibility)\nprint(\"üîß Force-downgrading NumPy to 1.x...\")\n!pip uninstall -y numpy 2>/dev/null || true\n!pip install -q --force-reinstall --no-deps \"numpy==1.26.4\"\n!pip install -q \"scikit-learn>=1.5.0,<1.6.0\"\n\n# Fix packages requiring NumPy 2.x (downgrade opencv if conflicting; ignore if unused)\n!pip install -q \"opencv-python==4.8.1.78\"  # Supports NumPy 1.x\n\n# Sentence-transformers (with deps now, post-NumPy fix)\n!pip install -q sentence-transformers\n\n# Optional SSR\n!pip install -q ssr-eval 2>/dev/null || echo \"‚ö†Ô∏è SSR skipped\"\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"‚úÖ Installs Complete! CRITICAL: RESTART RUNTIME NOW (Runtime > Restart session)\")\nprint(\"Then run this verification cell in a NEW cell:\")\nprint(\"=\"*50)\nprint(\"\"\"\nimport nest_asyncio; nest_asyncio.apply()\nimport lightning as pl, gradio as gr, numpy as np\nimport torch\n\nprint(f'‚úì PyTorch: {torch.__version__} | Lightning: {pl.__version__} | Gradio: {gr.__version__}')\nprint(f'‚úì NumPy: {np.__version__} (1.x confirmed) | CUDA: {torch.cuda.is_available()}')\n\nif torch.cuda.is_available():\n    print(f'‚úì GPU: {torch.cuda.get_device_name(0)} ({torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB)')\n\n# Key imports\nmodules = [\n    ('torchvision', 'TorchVision'), ('torchaudio', 'TorchAudio'), ('transformers', 'Transformers'),\n    ('torchmetrics', 'TorchMetrics'), ('datasets', 'Datasets')\n]\nfor mod_name, name in modules:\n    try:\n        __import__(mod_name); print(f'‚úì {name}: OK')\n    except Exception as e: print(f'‚ö†Ô∏è {name}: {str(e)[:50]}...')\n\ntry: from sentence_transformers import SentenceTransformer; print('‚úì Sentence-Transformers: OK')\nexcept Exception as e: print(f'‚ö†Ô∏è Sentence-Transformers: {str(e)[:50]}...')\n\ntry: from lightning.pytorch import LightningModule; print('‚úì Lightning/PyTorch Import: OK')\nexcept Exception as e: print(f'‚ö†Ô∏è Lightning Import: {str(e)[:50]}...')\n\nimport subprocess\nresult = subprocess.run(['pip', 'check'], capture_output=True, text=True)\nprint('‚úÖ No conflicts!' if 'no broken' in result.stdout.lower() else f'‚ö†Ô∏è Conflicts: {result.stdout[:150]}...')\n\nprint('\\\\nüéâ If all ‚úì, launch your app! For spaCy: !pip install \\\\\"thinc<8.3\\\\\"')\n\"\"\")\nprint(\"\\nüöÄ Restart now to load clean NumPy 1.x & resolve dynamo/circular imports.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üì• 2. Download Model Files\n\nWe'll download two model checkpoints:\n- **One-split (0.0-1.0)**: Full time range (~1.5GB)\n- **Two-split (0.5-1.0)**: Second time range (~1.5GB)\n\n**Total download: ~3GB. This will take 5-10 minutes.**","metadata":{}},{"cell_type":"code","source":"# Create checkpoint directory\n!mkdir -p ckpt\nprint(\"‚úì Checkpoint directory created\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\n\nprint(\"üì• Downloading model checkpoints...\\n\")\nprint(\"‚è±Ô∏è  This will take 5-10 minutes depending on your connection.\\n\")\n\n# Model files\nmodels = {\n    'onesplit': {\n        'path': 'ckpt/A2SB_onesplit_0.0_1.0_release.ckpt',\n        'url': 'https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge/resolve/main/ckpt/A2SB_onesplit_0.0_1.0_release.ckpt'\n    },\n    'twosplit': {\n        'path': 'ckpt/A2SB_twosplit_0.5_1.0_release.ckpt',\n        'url': 'https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge/resolve/main/ckpt/A2SB_twosplit_0.5_1.0_release.ckpt'\n    }\n}\n\n# Check and download each model\nfor name, info in models.items():\n    if os.path.exists(info['path']):\n        size_mb = os.path.getsize(info['path']) / (1024 * 1024)\n        print(f\"‚úì {name} model already exists ({size_mb:.2f} MB)\")\n    else:\n        print(f\"‚¨áÔ∏è  Downloading {name} model (~1.5GB)...\")\n        !wget -q --show-progress -O {info['path']} {info['url']}\n        if os.path.exists(info['path']):\n            size_mb = os.path.getsize(info['path']) / (1024 * 1024)\n            print(f\"‚úÖ {name} model downloaded ({size_mb:.2f} MB)\")\n        else:\n            print(f\"‚ùå Failed to download {name} model!\")\n            print(f\"Please check your internet connection and try again.\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"‚úÖ Model download complete!\")\nprint(\"=\"*50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## ‚öôÔ∏è 3. Configuration\n\nUpdate the configuration file with the correct model paths.","metadata":{}},{"cell_type":"code","source":"import yaml\n\nprint(\"‚öôÔ∏è  Updating configuration...\\n\")\n\n# Update config file\nconfig_path = 'configs/ensemble_2split_sampling.yaml'\nwith open(config_path, 'r') as f:\n    config = yaml.safe_load(f)\n\nconfig['model']['pretrained_checkpoints'] = [\n    'ckpt/A2SB_onesplit_0.0_1.0_release.ckpt',\n    'ckpt/A2SB_twosplit_0.5_1.0_release.ckpt'\n]\n\nwith open(config_path, 'w') as f:\n    yaml.dump(config, f)\n\nprint(\"‚úÖ Configuration updated successfully!\")\nprint(f\"\\nModel paths:\")\nfor i, path in enumerate(config['model']['pretrained_checkpoints'], 1):\n    print(f\"  {i}. {path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üé® 4. Launch Gradio Web Interface\n\n### üöÄ Ready to restore audio!\n\n**Features:**\n- üì§ Drag-and-drop file upload\n- üé§ Microphone recording\n- ‚öôÔ∏è Advanced settings (sampling steps, cutoff frequency)\n- üìä Real-time progress tracking\n- üîä Instant playback and comparison\n- üìà Spectral analysis visualization\n\n**How to use:**\n1. **Run the cell below** - Wait for the Gradio link to appear\n2. **Click the public link** (usually ends with `.gradio.live`)\n3. **Upload audio** or record from microphone\n4. **Choose mode:**\n   - **Bandwidth Extension**: Restore high frequencies (for low-quality MP3s)\n   - **Inpainting**: Fill in missing audio segments\n5. **Adjust settings** (optional):\n   - Sampling Steps: 25-100 (higher = better quality, slower)\n   - Auto Cutoff: Automatically detect cutoff frequency\n   - Inpainting Length: 0.1-1.0 seconds\n6. **Click \"üöÄ Restore\"** and wait for processing\n7. **Listen & Download** the restored audio\n\n**Tips:**\n- Start with default settings (50 steps, auto cutoff)\n- For faster results: 25-30 steps\n- For best quality: 75-100 steps\n- Processing time: ~2-3 minutes per 10 seconds of audio (on P100)\n\n**‚ö†Ô∏è Important:**\n- Keep this notebook tab open during processing\n- Don't close the Kaggle session\n- If you get \"Out of Memory\" error, reduce sampling steps or audio length\n- Gradio will create a public URL that expires after 72 hours","metadata":{}},{"cell_type":"code","source":"from pyngrok import ngrok\nimport os\nos.environ['NGROK_TOKEN'] = '2th59EQdTHjO8gP1GIetB9u7tdg_6rfJmEVKdwSDgnbh3yWtc'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Launch Gradio interface with public URL\nprint(\"üöÄ Launching Gradio interface...\\n\")\nprint(\"‚è±Ô∏è  Please wait for the link to appear below.\\n\")\nprint(\"=\"*60)\n\n%cd /kaggle/working/diffusion-audio-restoration-colab-Kaggle-\n\n# Kaggle i√ßin √∂zel gradio_app kullan\nimport os\nif os.path.exists('gradio_app_kaggle.py'):\n    print(\"‚úì Using Kaggle-optimized Gradio app\")\n    !python gradio_app_kaggle.py --share\nelse:\n    print(\"‚ö†Ô∏è Using default Gradio app\")\n    !python gradio_app.py --share\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"‚úÖ Gradio interface launched!\")\nprint(\"Click the public link above to access the web interface.\")\nprint(\"The link will be valid for 72 hours.\")\nprint(\"=\"*60)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-10-08T06:24:49.737Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%bash\nset -euo pipefail\n\nREPO_URL=\"https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git\"\nAPP_DIR=\"/kaggle/working/diffusion-audio-restoration-colab-Kaggle-\"\n\nif [ -d \"$APP_DIR/.git\" ]; then\n  echo \"‚úÖ Repo bulundu, g√ºncelleniyor...\"\n  cd \"$APP_DIR\"\n  git fetch --all --prune\n  git reset --hard origin/main\nelse\n  echo \"üì• Repo yok, klonlanƒ±yor...\"\n  rm -rf \"$APP_DIR\"\n  git clone --depth=1 \"$REPO_URL\" \"$APP_DIR\"\n  cd \"$APP_DIR\"\nfi\n\ngit config --global --add safe.directory \"$APP_DIR\"\nfind \"$APP_DIR\" -type d -name \"__pycache__\" -exec rm -rf {} + || true\n\necho \"‚úÖ G√ºncel commit:\"\ngit --no-pager log --oneline -1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üìö 5. Tips and Troubleshooting\n\n### ‚ö° Performance Optimization\n\n**GPU Requirements:**\n- ‚úÖ **Kaggle P100**: 16GB VRAM (Recommended)\n- ‚úÖ **Kaggle T4 x2**: 2x 16GB VRAM (Excellent)\n- ‚ö†Ô∏è **Kaggle T4**: 16GB VRAM (May work)\n\n**Processing Times (on P100 GPU):**\n- 10 seconds audio, 50 steps: ~2-3 minutes\n- 30 seconds audio, 50 steps: ~5-7 minutes\n- 60 seconds audio, 50 steps: ~10-15 minutes\n\n### üéØ Quality Settings\n\n**Sampling Steps:**\n- **25-30:** Fast (good quality)\n- **50-75:** Balanced (excellent quality) ‚≠ê Recommended\n- **75-100:** Best (outstanding quality)\n\n**Cutoff Frequency (Bandwidth Extension):**\n- **Auto-detect**: Usually best ‚≠ê Recommended\n- **Manual adjustment:**\n  - Low-quality MP3: 2000-4000 Hz\n  - Medium quality: 4000-8000 Hz\n  - High quality: 8000+ Hz\n\n**Inpainting Length:**\n- 0.1-0.3s: Small gaps or clicks\n- 0.3-0.5s: Medium gaps\n- 0.5-1.0s: Large missing segments\n\n### üîß Troubleshooting\n\n#### ‚ùå CUDA Out of Memory Error\n\n**Solutions:**\n1. **Reduce sampling steps** to 25-30\n2. **Split audio** into shorter segments (10-20 seconds)\n3. **Restart kernel**: Kernel > Restart Kernel\n4. **Clear GPU memory**: Run the cell below\n5. **Enable P100 GPU** in Kaggle settings\n\n```python\n# Clear GPU memory\nimport gc\nimport torch\ngc.collect()\ntorch.cuda.empty_cache()\nprint(\"‚úÖ GPU memory cleared\")\n```\n\n#### ‚ùå Model Not Found Error\n\n**Solutions:**\n1. Re-run the model download cells (Section 2)\n2. Check your internet connection\n3. Verify files exist:\n```python\n!ls -lh ckpt/\n```\n\n#### ‚ùå Gradio Interface Not Loading\n\n**Solutions:**\n1. Wait 30-60 seconds for the link to appear\n2. Check if the cell is still running\n3. Restart kernel and run all cells again\n4. Make sure you're using `--share` flag for public URL\n\n#### ‚ùå Audio Format Error\n\n**Solution:** Convert to WAV format\n```python\nimport librosa\nimport soundfile as sf\n\n# Convert any audio to WAV\ny, sr = librosa.load('input.mp3', sr=44100)\nsf.write('input.wav', y, sr)\n```\n\n#### ‚ö†Ô∏è Session Timeout\n\n**Solutions:**\n1. Kaggle provides 12 hours of continuous runtime\n2. Keep the tab active\n3. Process shorter audio files\n4. Save intermediate results to `/kaggle/working/`\n\n### üí° Best Practices\n\n1. **Start small**: Test with 10-20 second clips first\n2. **Use defaults**: 50 steps, auto cutoff works well\n3. **Monitor GPU**: Check `nvidia-smi` if issues occur\n4. **Save outputs**: Download restored audio immediately\n5. **Batch processing**: Process multiple files one at a time\n6. **Use Kaggle Datasets**: Upload your audio files as a Kaggle dataset for easier access\n\n### üìÅ Kaggle File System\n\n**Important directories:**\n- `/kaggle/input/`: Read-only input data (datasets)\n- `/kaggle/working/`: Writable directory (your work)\n- `/kaggle/temp/`: Temporary files\n\n**Upload audio files:**\n1. Create a Kaggle dataset with your audio files\n2. Add the dataset to your notebook\n3. Access files from `/kaggle/input/your-dataset-name/`\n\n**Download results:**\n- Restored audio files are saved in `/kaggle/working/`\n- Click the \"Output\" tab to download files\n- Or use the Gradio interface to download directly\n\n### üìñ License and Usage\n\n- **Model:** NVIDIA OneWay NonCommercial License\n- **Code:** NVIDIA Source Code License - Non Commercial\n- **Commercial Use:** Contact NVIDIA for licensing\n- **Research Use:** Free for academic and research purposes\n\n### üîó Additional Resources\n\n- **Paper:** [arXiv:2501.11311](https://arxiv.org/abs/2501.11311)\n- **GitHub:** [test4373/diffusion-audio-restoration](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n- **Original NVIDIA Repo:** [NVIDIA/diffusion-audio-restoration](https://github.com/NVIDIA/diffusion-audio-restoration)\n- **Demo:** [NVIDIA Research](https://research.nvidia.com/labs/adlr/A2SB/)\n- **Models:** [HuggingFace](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n\n### üìß Support\n\n- **Issues:** [GitHub Issues](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-/issues)\n- **Original NVIDIA Issues:** [NVIDIA GitHub](https://github.com/NVIDIA/diffusion-audio-restoration/issues)\n- **Kaggle Community:** [Kaggle Forums](https://www.kaggle.com/discussions)\n\n---\n\n### üéâ Thank You!\n\nThank you for using this notebook on Kaggle!\n\n**Citation:**\n```bibtex\n@article{kong2025a2sb,\n  title={A2SB: Audio-to-Audio Schrodinger Bridges},\n  author={Kong, Zhifeng and Shih, Kevin J and Nie, Weili and Vahdat, Arash and Lee, Sang-gil and Santos, Joao Felipe and Jukic, Ante and Valle, Rafael and Catanzaro, Bryan},\n  journal={arXiv preprint arXiv:2501.11311},\n  year={2025}\n}\n```\n\n### ‚≠ê Support This Project\n\nIf you find this project useful:\n- ‚≠ê Star the [GitHub repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n- üêõ Report bugs or suggest features\n- üì¢ Share with others who might benefit\n- üëç Upvote this Kaggle notebook\n\n---\n\n**Made with ‚ù§Ô∏è for the audio restoration community**\n\n**Optimized for Kaggle with GPU memory management and user-friendly interface**\n\n### üÜì Why Kaggle?\n\nKaggle offers several advantages:\n- **Free GPU access**: 30 hours per week\n- **Powerful hardware**: P100 GPU with 16GB VRAM\n- **Generous resources**: 30GB RAM, 73GB disk\n- **Persistent storage**: Save your work and models\n- **Community**: Share and collaborate with others\n- **No subscription**: Completely free!\n\nPerfect for audio restoration projects! üéµ","metadata":{}}]}