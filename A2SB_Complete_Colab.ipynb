{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéµ A2SB: Audio-to-Audio Schr√∂dinger Bridge - Complete Edition\n",
    "\n",
    "**High-Quality Audio Restoration with NVIDIA A2SB**\n",
    "\n",
    "This notebook includes **everything** you need: model download, setup, and Gradio web interface!\n",
    "\n",
    "## üåü Features\n",
    "- ‚úÖ 44.1kHz high-resolution music restoration\n",
    "- ‚úÖ Bandwidth extension (high-frequency prediction)\n",
    "- ‚úÖ Audio inpainting (reconstruct missing segments)\n",
    "- ‚úÖ Support for long audio files (hours)\n",
    "- ‚úÖ End-to-end, no vocoder required\n",
    "- ‚úÖ **Gradio Web Interface** - User-friendly UI\n",
    "\n",
    "## üìö Resources\n",
    "- üìÑ [Paper](https://arxiv.org/abs/2501.11311)\n",
    "- üíª [GitHub](https://github.com/NVIDIA/diffusion-audio-restoration)\n",
    "- üé¨ [Demo](https://research.nvidia.com/labs/adlr/A2SB/)\n",
    "- ü§ó [Models](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
    "\n",
    "---\n",
    "\n",
    "**Usage:** Run cells in order. The last cell will launch the Gradio interface!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üì¶ 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/NVIDIA/diffusion-audio-restoration.git\n",
    "%cd diffusion-audio-restoration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "print(\"üì¶ Starting installation...\\n\")\n",
    "\n",
    "# 1. Update basic packages\n",
    "print(\"1Ô∏è‚É£ Updating basic packages...\")\n",
    "!pip install -q --upgrade pip setuptools wheel\n",
    "\n",
    "# 2. PyTorch and torchaudio (CUDA-enabled)\n",
    "print(\"2Ô∏è‚É£ Installing PyTorch (CUDA 11.8)...\")\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# 3. Audio processing libraries\n",
    "print(\"3Ô∏è‚É£ Installing audio processing libraries...\")\n",
    "!pip install -q numpy scipy matplotlib librosa soundfile\n",
    "\n",
    "# 4. Lightning (important!)\n",
    "print(\"4Ô∏è‚É£ Installing PyTorch Lightning...\")\n",
    "!pip install -q lightning \"pytorch-lightning>=2.0.0\"\n",
    "\n",
    "# 5. Other deep learning libraries\n",
    "print(\"5Ô∏è‚É£ Installing other deep learning libraries...\")\n",
    "!pip install -q einops\n",
    "\n",
    "# 6. Gradio and jsonargparse\n",
    "print(\"6Ô∏è‚É£ Installing Gradio and jsonargparse...\")\n",
    "!pip install -q \"jsonargparse[signatures]>=4.0.0\" gradio\n",
    "\n",
    "# 7. Rotary embedding (optional)\n",
    "print(\"7Ô∏è‚É£ Installing optional packages...\")\n",
    "!pip install -q rotary-embedding-torch 2>/dev/null || echo \"‚ö†Ô∏è rotary-embedding-torch skipped (optional)\"\n",
    "\n",
    "# 8. SSR Eval (required!)\n",
    "print(\"8Ô∏è‚É£ Installing SSR Eval...\")\n",
    "!pip install -q ssr-eval || pip install -q git+https://github.com/speechbrain/ssr-eval.git || echo \"‚ö†Ô∏è ssr_eval could not be installed, continuing...\"\n",
    "\n",
    "# 9. Nest-asyncio (for Gradio event loop fix)\n",
    "print(\"9Ô∏è‚É£ Installing nest-asyncio...\")\n",
    "!pip install -q nest-asyncio\n",
    "\n",
    "# 10. Check versions\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Installation complete! Version check:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "import lightning\n",
    "import gradio as gr\n",
    "import nest_asyncio\n",
    "\n",
    "# Fix event loop issue\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(f\"‚úì PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úì Lightning: {lightning.__version__}\")\n",
    "print(f\"‚úì Gradio: {gr.__version__}\")\n",
    "print(f\"‚úì CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# SSR Eval check\n",
    "try:\n",
    "    import ssr_eval\n",
    "    print(f\"‚úì SSR Eval: Installed\")\n",
    "except ImportError:\n",
    "    print(f\"‚ö†Ô∏è SSR Eval: Not installed (optional)\")\n",
    "\n",
    "print(\"\\nüéâ All libraries successfully installed!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_models"
   },
   "source": [
    "## üì• 2. Download Model Files\n",
    "\n",
    "We'll download two model checkpoints:\n",
    "- **One-split (0.0-1.0)**: Full time range\n",
    "- **Two-split (0.5-1.0)**: Second time range\n",
    "\n",
    "**Note:** Each model is approximately 1.5GB. Download may take 5-10 minutes depending on your connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_checkpoint_dir"
   },
   "outputs": [],
   "source": [
    "# Create checkpoint directory\n",
    "!mkdir -p ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_models"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Model files\n",
    "models = {\n",
    "    'onesplit': {\n",
    "        'path': 'ckpt/A2SB_onesplit_0.0_1.0_release.ckpt',\n",
    "        'url': 'https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge/resolve/main/ckpt/A2SB_onesplit_0.0_1.0_release.ckpt'\n",
    "    },\n",
    "    'twosplit': {\n",
    "        'path': 'ckpt/A2SB_twosplit_0.5_1.0_release.ckpt',\n",
    "        'url': 'https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge/resolve/main/ckpt/A2SB_twosplit_0.5_1.0_release.ckpt'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check and download each model\n",
    "for name, info in models.items():\n",
    "    if os.path.exists(info['path']):\n",
    "        size_mb = os.path.getsize(info['path']) / (1024 * 1024)\n",
    "        print(f\"‚úì {name} model already exists ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"‚¨á Downloading {name} model...\")\n",
    "        !wget -O {info['path']} {info['url']}\n",
    "        if os.path.exists(info['path']):\n",
    "            size_mb = os.path.getsize(info['path']) / (1024 * 1024)\n",
    "            print(f\"‚úì {name} model downloaded ({size_mb:.2f} MB)\")\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to download {name} model!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model download complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "update_config"
   },
   "source": [
    "## ‚öôÔ∏è 3. Configuration\n",
    "\n",
    "Update the configuration file with the correct model paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "update_config_file"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Update config file\n",
    "config_path = 'configs/ensemble_2split_sampling.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['model']['pretrained_checkpoints'] = [\n",
    "    'ckpt/A2SB_onesplit_0.0_1.0_release.ckpt',\n",
    "    'ckpt/A2SB_twosplit_0.5_1.0_release.ckpt'\n",
    "]\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"‚úì Configuration updated\")\n",
    "print(f\"Model paths: {config['model']['pretrained_checkpoints']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gradio_ui"
   },
   "source": [
    "## üé® 4. Launch Gradio Web Interface\n",
    "\n",
    "### User-friendly web interface for audio restoration!\n",
    "\n",
    "**Features:**\n",
    "- üì§ Drag-and-drop file upload\n",
    "- üé§ Microphone recording\n",
    "- ‚öôÔ∏è Advanced settings\n",
    "- üìä Real-time progress\n",
    "- üîä Instant playback and comparison\n",
    "\n",
    "**How to use:**\n",
    "1. Run the cell below\n",
    "2. Click on the generated link (usually ends with `.gradio.live`)\n",
    "3. Upload your audio file or record from microphone\n",
    "4. Choose restoration mode:\n",
    "   - **Bandwidth Extension**: Restore high frequencies (for low-quality audio)\n",
    "   - **Inpainting**: Fill in missing audio segments\n",
    "5. Adjust settings if needed (or use defaults)\n",
    "6. Click \"üöÄ Restore\" and wait for processing\n",
    "7. Listen to the restored audio and download if satisfied\n",
    "\n",
    "**Tips:**\n",
    "- Start with default settings (50 steps, auto cutoff)\n",
    "- For faster results, reduce sampling steps to 25-30\n",
    "- For best quality, increase sampling steps to 75-100\n",
    "- Processing time: ~2-3 minutes per 10 seconds of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gradio_app"
   },
   "outputs": [],
   "source": [
    "# Launch Gradio interface\n",
    "!python gradio_app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "## üìö 5. Tips and Troubleshooting\n",
    "\n",
    "### ‚ö° Performance Optimization\n",
    "\n",
    "**GPU Requirements:**\n",
    "- CUDA-enabled NVIDIA GPU required\n",
    "- Minimum 8GB GPU memory recommended\n",
    "- 16GB+ GPU memory for long audio files\n",
    "\n",
    "**Processing Times (Approximate):**\n",
    "- 10 seconds audio, 50 steps: ~2-3 minutes\n",
    "- 30 seconds audio, 50 steps: ~5-7 minutes\n",
    "- 60 seconds audio, 50 steps: ~10-15 minutes\n",
    "\n",
    "### üéØ Quality Settings\n",
    "\n",
    "**Sampling Steps:**\n",
    "- **25-50:** Fast prototyping\n",
    "- **50-75:** Production quality (recommended)\n",
    "- **75-100:** Maximum quality\n",
    "\n",
    "**Cutoff Frequency (for Bandwidth Extension):**\n",
    "- Auto-detection usually works best\n",
    "- Manual adjustment guide:\n",
    "  - Low-quality MP3: 2000-4000 Hz\n",
    "  - Medium quality: 4000-8000 Hz\n",
    "  - High quality: 8000+ Hz\n",
    "\n",
    "**Inpainting Length:**\n",
    "- 0.1-0.3s: Small gaps or clicks\n",
    "- 0.3-0.5s: Medium gaps\n",
    "- 0.5-1.0s: Large missing segments\n",
    "\n",
    "### üîß Troubleshooting\n",
    "\n",
    "**CUDA Out of Memory Error:**\n",
    "```python\n",
    "# Solution 1: Split audio into shorter segments\n",
    "# Solution 2: Reduce sampling steps\n",
    "# Solution 3: Use Colab Pro (more RAM/GPU)\n",
    "# Solution 4: Restart runtime and clear GPU memory\n",
    "```\n",
    "\n",
    "**Model Not Found Error:**\n",
    "- Re-run the model download cells\n",
    "- Check your internet connection\n",
    "- Verify files exist in `ckpt/` directory\n",
    "\n",
    "**Audio Format Error:**\n",
    "```python\n",
    "# Convert audio to WAV format\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "y, sr = librosa.load('input.mp3', sr=44100)\n",
    "sf.write('input.wav', y, sr)\n",
    "```\n",
    "\n",
    "**Gradio Interface Not Loading:**\n",
    "```python\n",
    "# Fix event loop issue\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "```\n",
    "\n",
    "**Slow Processing:**\n",
    "- Ensure GPU is being used (check `nvidia-smi`)\n",
    "- Close other GPU-intensive applications\n",
    "- Reduce audio length or sampling steps\n",
    "\n",
    "### üìñ License and Usage\n",
    "\n",
    "- **Model:** NVIDIA OneWay NonCommercial License\n",
    "- **Code:** NVIDIA Source Code License - Non Commercial\n",
    "- **Commercial Use:** Contact NVIDIA for licensing\n",
    "- **Research Use:** Free for academic and research purposes\n",
    "\n",
    "### üîó Additional Resources\n",
    "\n",
    "- **Paper:** [arXiv:2501.11311](https://arxiv.org/abs/2501.11311)\n",
    "- **GitHub:** [NVIDIA/diffusion-audio-restoration](https://github.com/NVIDIA/diffusion-audio-restoration)\n",
    "- **Demo:** [NVIDIA Research](https://research.nvidia.com/labs/adlr/A2SB/)\n",
    "- **Models:** [HuggingFace](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
    "\n",
    "### üìß Support\n",
    "\n",
    "- **Issues:** [GitHub Issues](https://github.com/NVIDIA/diffusion-audio-restoration/issues)\n",
    "- **Research Inquiries:** [NVIDIA Research](https://www.nvidia.com/en-us/research/inquiries/)\n",
    "\n",
    "---\n",
    "\n",
    "### üéâ Thank You!\n",
    "\n",
    "Thank you for using this notebook. For questions or feedback, please use GitHub Issues.\n",
    "\n",
    "**Citation:**\n",
    "```bibtex\n",
    "@article{kong2025a2sb,\n",
    "  title={A2SB: Audio-to-Audio Schrodinger Bridges},\n",
    "  author={Kong, Zhifeng and Shih, Kevin J and Nie, Weili and Vahdat, Arash and Lee, Sang-gil and Santos, Joao Felipe and Jukic, Ante and Valle, Rafael and Catanzaro, Bryan},\n",
    "  journal={arXiv preprint arXiv:2501.11311},\n",
    "  year={2025}\n",
    "}\n",
    "```\n",
    "\n",
    "### üåü Star the Repository!\n",
    "\n",
    "If you find this project useful, please consider starring the [GitHub repository](https://github.com/NVIDIA/diffusion-audio-restoration)!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
