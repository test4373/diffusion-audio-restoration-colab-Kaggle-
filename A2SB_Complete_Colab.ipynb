{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üéµ A2SB: Audio Restoration - Google Colab\n",
        "\n",
        "**High-Quality Audio Restoration with NVIDIA A2SB**\n",
        "\n",
        "Restore your audio files with AI!\n",
        "\n",
        "## üöÄ Features\n",
        "- ‚úÖ 44.1kHz high-resolution audio restoration\n",
        "- ‚úÖ Bandwidth extension (high-frequency prediction)\n",
        "- ‚úÖ Audio inpainting (fill missing parts)\n",
        "- ‚úÖ User-friendly Gradio interface\n",
        "\n",
        "## üìã Requirements\n",
        "- üéØ **GPU**: T4 or better (Colab Pro recommended)\n",
        "- üíæ **RAM**: Minimum 12GB\n",
        "- ‚è±Ô∏è **Time**: ~2-3 minutes for 10 seconds of audio\n",
        "\n",
        "## üìö Resources\n",
        "- üìÑ [Paper](https://arxiv.org/abs/2501.11311)\n",
        "- üíª [GitHub](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
        "- ü§ó [Models](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
        "\n",
        "---\n",
        "\n",
        "**Usage:** Run cells in order. The last cell will launch the Gradio interface!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step1"
      },
      "source": [
        "## üì¶ Step 1: Setup (5-10 minutes)\n",
        "\n",
        "Clone the repository and install required libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# Clone repository\n",
        "print(\"üì• Cloning repository...\\n\")\n",
        "!git clone https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git\n",
        "%cd diffusion-audio-restoration-colab-Kaggle-\n",
        "\n",
        "# Install libraries\n",
        "print(\"\\nüì¶ Installing libraries... (5-10 minutes)\\n\")\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q nest-asyncio\n",
        "\n",
        "# Verification\n",
        "import torch\n",
        "import gradio as gr\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\n‚úì PyTorch: {torch.__version__}\")\n",
        "print(f\"‚úì Gradio: {gr.__version__}\")\n",
        "print(f\"‚úì CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"‚úì GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "print(\"\\nüéâ Ready!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step2"
      },
      "source": [
        "## üì• Step 2: Download Models (5-10 minutes)\n",
        "\n",
        "Download two model checkpoints (~4.5GB total)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create checkpoint directory\n",
        "!mkdir -p ckpt\n",
        "\n",
        "print(\"üì• Downloading models... (5-10 minutes)\\n\")\n",
        "\n",
        "# Model 1: One-split (0.0-1.0)\n",
        "model1 = 'ckpt/A2SB_onesplit_0.0_1.0_release.ckpt'\n",
        "if not os.path.exists(model1):\n",
        "    print(\"‚¨áÔ∏è  Downloading Model 1... (~2.3GB)\")\n",
        "    !wget -q --show-progress https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge/resolve/main/ckpt/A2SB_onesplit_0.0_1.0_release.ckpt -O {model1}\n",
        "    print(\"‚úÖ Model 1 downloaded!\\n\")\n",
        "else:\n",
        "    print(\"‚úì Model 1 already exists\\n\")\n",
        "\n",
        "# Model 2: Two-split (0.5-1.0)\n",
        "model2 = 'ckpt/A2SB_twosplit_0.5_1.0_release.ckpt'\n",
        "if not os.path.exists(model2):\n",
        "    print(\"‚¨áÔ∏è  Downloading Model 2... (~2.3GB)\")\n",
        "    !wget -q --show-progress https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge/resolve/main/ckpt/A2SB_twosplit_0.5_1.0_release.ckpt -O {model2}\n",
        "    print(\"‚úÖ Model 2 downloaded!\\n\")\n",
        "else:\n",
        "    print(\"ÔøΩÔøΩ Model 2 already exists\\n\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"‚úÖ All models ready!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step3"
      },
      "source": [
        "## ‚öôÔ∏è Step 3: Configuration\n",
        "\n",
        "Set up model paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "config"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "print(\"‚öôÔ∏è  Updating configuration...\\n\")\n",
        "\n",
        "config_path = 'configs/ensemble_2split_sampling.yaml'\n",
        "with open(config_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "config['model']['pretrained_checkpoints'] = [\n",
        "    'ckpt/A2SB_onesplit_0.0_1.0_release.ckpt',\n",
        "    'ckpt/A2SB_twosplit_0.5_1.0_release.ckpt'\n",
        "]\n",
        "\n",
        "with open(config_path, 'w') as f:\n",
        "    yaml.dump(config, f)\n",
        "\n",
        "print(\"‚úÖ Configuration updated!\")\n",
        "print(f\"\\nModel paths:\")\n",
        "for i, path in enumerate(config['model']['pretrained_checkpoints'], 1):\n",
        "    print(f\"  {i}. {path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "step4"
      },
      "source": [
        "## üé® Step 4: Launch Gradio Interface\n",
        "\n",
        "### üöÄ Ready to restore audio!\n",
        "\n",
        "**How to use:**\n",
        "1. Run the cell below\n",
        "2. Click the link (ends with `.gradio.live`)\n",
        "3. Upload audio file or record from microphone\n",
        "4. Choose mode:\n",
        "   - **Bandwidth Extension**: Restore high frequencies (for low-quality MP3s)\n",
        "   - **Inpainting**: Fill missing parts\n",
        "5. Click \"üöÄ Restore\"\n",
        "6. Listen and download the result!\n",
        "\n",
        "**Settings:**\n",
        "- **Sampling Steps**: 25-100 (higher = better quality, slower)\n",
        "  - Fast: 25-30 steps\n",
        "  - Balanced: 50 steps ‚≠ê Recommended\n",
        "  - Best: 75-100 steps\n",
        "- **Auto Cutoff**: Automatically detect cutoff frequency ‚≠ê Recommended\n",
        "- **Inpainting Length**: 0.1-1.0 seconds\n",
        "\n",
        "**Processing Times (T4 GPU):**\n",
        "- 10s audio, 50 steps: ~2-3 minutes\n",
        "- 30s audio, 50 steps: ~5-7 minutes\n",
        "- 60s audio, 50 steps: ~10-15 minutes\n",
        "\n",
        "**‚ö†Ô∏è Important:**\n",
        "- Keep the notebook open during processing\n",
        "- If you get \"Out of Memory\" error, reduce sampling steps\n",
        "- Test with short audio files first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "launch"
      },
      "outputs": [],
      "source": [
        "# Launch Gradio interface\n",
        "print(\"üöÄ Launching Gradio interface...\\n\")\n",
        "print(\"‚è±Ô∏è  Please wait for the link to appear.\\n\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "!python gradio_app.py\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ Gradio interface launched!\")\n",
        "print(\"Click the link above to access the interface.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tips"
      },
      "source": [
        "## üí° Tips and Troubleshooting\n",
        "\n",
        "### ‚ö° Performance\n",
        "\n",
        "**GPU Requirements:**\n",
        "- ‚úÖ T4 (16GB) - Colab Pro\n",
        "- ‚úÖ V100 (32GB) - Colab Pro+\n",
        "- ‚úÖ A100 (40GB) - Colab Pro+\n",
        "- ‚ö†Ô∏è Free Colab - May get memory errors\n",
        "\n",
        "### üéØ Quality Settings\n",
        "\n",
        "**Sampling Steps:**\n",
        "- 25-30: Fast (good quality)\n",
        "- 50-75: Balanced (excellent quality) ‚≠ê\n",
        "- 75-100: Best (outstanding quality)\n",
        "\n",
        "**Cutoff Frequency (Bandwidth Extension):**\n",
        "- Auto-detect: Usually best ‚≠ê\n",
        "- Manual:\n",
        "  - Low-quality MP3: 2000-4000 Hz\n",
        "  - Medium quality: 4000-8000 Hz\n",
        "  - High quality: 8000+ Hz\n",
        "\n",
        "### ‚ùå Common Errors\n",
        "\n",
        "**\"Out of Memory\" Error:**\n",
        "- Reduce sampling steps (25-30)\n",
        "- Use shorter audio files\n",
        "- Upgrade to Colab Pro\n",
        "\n",
        "**Session Timeout:**\n",
        "- Use Colab Pro (longer sessions)\n",
        "- Keep tab active\n",
        "- Process shorter audio files\n",
        "\n",
        "### üìñ License\n",
        "\n",
        "- **Model**: NVIDIA OneWay NonCommercial License\n",
        "- **Code**: NVIDIA Source Code License - Non Commercial\n",
        "- **Commercial Use**: Contact NVIDIA for licensing\n",
        "- **Research**: Free for academic and research purposes\n",
        "\n",
        "### üîó Additional Resources\n",
        "\n",
        "- **Paper**: [arXiv:2501.11311](https://arxiv.org/abs/2501.11311)\n",
        "- **GitHub**: [test4373/diffusion-audio-restoration](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
        "- **NVIDIA Demo**: [research.nvidia.com](https://research.nvidia.com/labs/adlr/A2SB/)\n",
        "- **Models**: [HuggingFace](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
        "\n",
        "---\n",
        "\n",
        "### üéâ Thank You!\n",
        "\n",
        "Thank you for using this notebook!\n",
        "\n",
        "**Citation:**\n",
        "```bibtex\n",
        "@article{kong2025a2sb,\n",
        "  title={A2SB: Audio-to-Audio Schrodinger Bridges},\n",
        "  author={Kong, Zhifeng and Shih, Kevin J and Nie, Weili and Vahdat, Arash and Lee, Sang-gil and Santos, Joao Felipe and Jukic, Ante and Valle, Rafael and Catanzaro, Bryan},\n",
        "  journal={arXiv preprint arXiv:2501.11311},\n",
        "  year={2025}\n",
        "}\n",
        "```\n",
        "\n",
        "### ‚≠ê Support This Project\n",
        "\n",
        "If you find this useful:\n",
        "- ‚≠ê Star the [GitHub repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
        "- üêõ Report bugs or suggest features\n",
        "- üì¢ Share with others\n",
        "\n",
        "---\n",
        "\n",
        "**‚ù§Ô∏è Made for the audio restoration community**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
