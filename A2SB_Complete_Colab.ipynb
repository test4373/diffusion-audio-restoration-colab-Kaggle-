{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéµ A2SB: Audio-to-Audio Schr√∂dinger Bridge - Complete Edition\n",
    "\n",
    "**High-Quality Audio Restoration with NVIDIA A2SB**\n",
    "\n",
    "This notebook includes **everything** you need: model download, setup, and Gradio web interface!\n",
    "\n",
    "## ‚ö†Ô∏è IMPORTANT: Colab Pro Required\n",
    "\n",
    "**This notebook requires Google Colab Pro or Colab Pro+ subscription!**\n",
    "\n",
    "### Why Colab Pro?\n",
    "- üéØ **GPU Memory**: Requires 15GB+ GPU VRAM (T4 or better)\n",
    "- ‚è±Ô∏è **Processing Time**: Long audio files need extended runtime\n",
    "- üíæ **RAM**: Minimum 25GB system RAM recommended\n",
    "- üöÄ **Performance**: Better GPUs (V100/A100) for faster processing\n",
    "\n",
    "### Free Colab Limitations:\n",
    "- ‚ùå Limited GPU memory (may cause Out of Memory errors)\n",
    "- ‚ùå Short session timeouts\n",
    "- ‚ùå Lower priority GPU access\n",
    "- ‚ùå May disconnect during long processing\n",
    "\n",
    "### Get Colab Pro:\n",
    "üëâ [Subscribe to Colab Pro](https://colab.research.google.com/signup) - Starting at $9.99/month\n",
    "\n",
    "---\n",
    "\n",
    "## üåü Features\n",
    "- ‚úÖ 44.1kHz high-resolution music restoration\n",
    "- ‚úÖ Bandwidth extension (high-frequency prediction)\n",
    "- ‚úÖ Audio inpainting (reconstruct missing segments)\n",
    "- ‚úÖ Support for long audio files (hours)\n",
    "- ‚úÖ End-to-end, no vocoder required\n",
    "- ‚úÖ **Gradio Web Interface** - User-friendly UI\n",
    "\n",
    "## üìö Resources\n",
    "- üìÑ [Paper](https://arxiv.org/abs/2501.11311)\n",
    "- üíª [GitHub Repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- üé¨ [Original NVIDIA Demo](https://research.nvidia.com/labs/adlr/A2SB/)\n",
    "- ü§ó [Models](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
    "\n",
    "---\n",
    "\n",
    "**Usage:** Run cells in order. The last cell will launch the Gradio interface!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check_subscription"
   },
   "source": [
    "## üîç Step 0: Check Your Colab Subscription\n",
    "\n",
    "**Run this cell to verify your GPU and subscription status.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_colab_pro"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîç CHECKING COLAB ENVIRONMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check GPU\n",
    "try:\n",
    "    gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'], text=True)\n",
    "    gpu_name, gpu_memory = gpu_info.strip().split(', ')\n",
    "    gpu_memory_gb = int(gpu_memory.split()[0]) / 1024\n",
    "    \n",
    "    print(f\"\\n‚úì GPU Detected: {gpu_name}\")\n",
    "    print(f\"‚úì GPU Memory: {gpu_memory_gb:.1f} GB\")\n",
    "    \n",
    "    # Check if sufficient\n",
    "    if gpu_memory_gb < 14:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚ö†Ô∏è  WARNING: INSUFFICIENT GPU MEMORY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Your GPU has {gpu_memory_gb:.1f} GB memory.\")\n",
    "        print(\"This notebook requires at least 15GB GPU memory.\")\n",
    "        print(\"\\nüî¥ RECOMMENDATION: Upgrade to Colab Pro for better GPUs!\")\n",
    "        print(\"\\nYou may experience:\")\n",
    "        print(\"  - Out of Memory errors\")\n",
    "        print(\"  - Failed inference\")\n",
    "        print(\"  - Slow processing\")\n",
    "        print(\"\\nüëâ Get Colab Pro: https://colab.research.google.com/signup\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"\\n‚úÖ GPU memory is sufficient!\")\n",
    "        if 'V100' in gpu_name or 'A100' in gpu_name or 'P100' in gpu_name:\n",
    "            print(\"üéâ You have a premium GPU! (Colab Pro detected)\")\n",
    "        elif 'T4' in gpu_name:\n",
    "            print(\"‚úì T4 GPU detected - Good for this notebook\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(\"\\n‚ùå ERROR: No GPU detected!\")\n",
    "    print(\"\\nPlease enable GPU:\")\n",
    "    print(\"1. Go to Runtime > Change runtime type\")\n",
    "    print(\"2. Select 'GPU' as Hardware accelerator\")\n",
    "    print(\"3. Click Save\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Check RAM\n",
    "try:\n",
    "    with open('/proc/meminfo', 'r') as f:\n",
    "        meminfo = f.read()\n",
    "    mem_total = int([line for line in meminfo.split('\\n') if 'MemTotal' in line][0].split()[1]) / 1024 / 1024\n",
    "    print(f\"\\n‚úì System RAM: {mem_total:.1f} GB\")\n",
    "    \n",
    "    if mem_total < 20:\n",
    "        print(\"‚ö†Ô∏è  Low RAM detected. Consider upgrading to Colab Pro for 25GB+ RAM.\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Environment check complete!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nIf you see warnings above, we strongly recommend:\")\n",
    "print(\"üëâ Upgrade to Colab Pro: https://colab.research.google.com/signup\")\n",
    "print(\"\\nOtherwise, you may proceed at your own risk.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üì¶ 1. Setup and Dependencies\n",
    "\n",
    "**This will take 5-10 minutes. Please be patient!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone the optimized repository\n",
    "print(\"üì• Cloning repository...\\n\")\n",
    "!git clone https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git\n",
    "%cd diffusion-audio-restoration-colab-Kaggle-\n",
    "print(\"\\n‚úÖ Repository cloned successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required libraries using requirements.txt\n",
    "print(\"üì¶ Installing dependencies from requirements.txt...\\n\")\n",
    "print(\"‚è±Ô∏è  This will take 5-10 minutes. Please wait...\\n\")\n",
    "\n",
    "# Install from requirements.txt\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Install PyTorch with CUDA support (if not already installed)\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install nest-asyncio for Gradio\n",
    "!pip install -q nest-asyncio\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Installation complete! Verifying...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "import lightning\n",
    "import gradio as gr\n",
    "import nest_asyncio\n",
    "\n",
    "# Fix event loop issue\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(f\"\\n‚úì PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úì Lightning: {lightning.__version__}\")\n",
    "print(f\"‚úì Gradio: {gr.__version__}\")\n",
    "print(f\"‚úì CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úì GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# SSR Eval check\n",
    "try:\n",
    "    import ssr_eval\n",
    "    print(f\"‚úì SSR Eval: Installed\")\n",
    "except ImportError:\n",
    "    print(f\"‚ö†Ô∏è SSR Eval: Not installed (optional)\")\n",
    "\n",
    "print(\"\\nüéâ All libraries successfully installed!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download_models"
   },
   "source": [
    "## üì• 2. Download Model Files\n",
    "\n",
    "We'll download two model checkpoints:\n",
    "- **One-split (0.0-1.0)**: Full time range (~1.5GB)\n",
    "- **Two-split (0.5-1.0)**: Second time range (~1.5GB)\n",
    "\n",
    "**Total download: ~3GB. This will take 5-10 minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_checkpoint_dir"
   },
   "outputs": [],
   "source": [
    "# Create checkpoint directory\n",
    "!mkdir -p ckpt\n",
    "print(\"‚úì Checkpoint directory created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_models"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"üì• Downloading model checkpoints...\\n\")\n",
    "print(\"‚è±Ô∏è  This will take 5-10 minutes depending on your connection.\\n\")\n",
    "\n",
    "# Model files\n",
    "models = {\n",
    "    'onesplit': {\n",
    "        'path': 'ckpt/A2SB_onesplit_0.0_1.0_release.ckpt',\n",
    "        'url': 'https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge/resolve/main/ckpt/A2SB_onesplit_0.0_1.0_release.ckpt'\n",
    "    },\n",
    "    'twosplit': {\n",
    "        'path': 'ckpt/A2SB_twosplit_0.5_1.0_release.ckpt',\n",
    "        'url': 'https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge/resolve/main/ckpt/A2SB_twosplit_0.5_1.0_release.ckpt'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Check and download each model\n",
    "for name, info in models.items():\n",
    "    if os.path.exists(info['path']):\n",
    "        size_mb = os.path.getsize(info['path']) / (1024 * 1024)\n",
    "        print(f\"‚úì {name} model already exists ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"‚¨áÔ∏è  Downloading {name} model (~1.5GB)...\")\n",
    "        !wget -q --show-progress -O {info['path']} {info['url']}\n",
    "        if os.path.exists(info['path']):\n",
    "            size_mb = os.path.getsize(info['path']) / (1024 * 1024)\n",
    "            print(f\"‚úÖ {name} model downloaded ({size_mb:.2f} MB)\")\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to download {name} model!\")\n",
    "            print(f\"Please check your internet connection and try again.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ Model download complete!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "update_config"
   },
   "source": [
    "## ‚öôÔ∏è 3. Configuration\n",
    "\n",
    "Update the configuration file with the correct model paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "update_config_file"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "print(\"‚öôÔ∏è  Updating configuration...\\n\")\n",
    "\n",
    "# Update config file\n",
    "config_path = 'configs/ensemble_2split_sampling.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "config['model']['pretrained_checkpoints'] = [\n",
    "    'ckpt/A2SB_onesplit_0.0_1.0_release.ckpt',\n",
    "    'ckpt/A2SB_twosplit_0.5_1.0_release.ckpt'\n",
    "]\n",
    "\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"‚úÖ Configuration updated successfully!\")\n",
    "print(f\"\\nModel paths:\")\n",
    "for i, path in enumerate(config['model']['pretrained_checkpoints'], 1):\n",
    "    print(f\"  {i}. {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gradio_ui"
   },
   "source": [
    "## üé® 4. Launch Gradio Web Interface\n",
    "\n",
    "### üöÄ Ready to restore audio!\n",
    "\n",
    "**Features:**\n",
    "- üì§ Drag-and-drop file upload\n",
    "- üé§ Microphone recording\n",
    "- ‚öôÔ∏è Advanced settings (sampling steps, cutoff frequency)\n",
    "- üìä Real-time progress tracking\n",
    "- üîä Instant playback and comparison\n",
    "- üìà Spectral analysis visualization\n",
    "\n",
    "**How to use:**\n",
    "1. **Run the cell below** - Wait for the Gradio link to appear\n",
    "2. **Click the link** (usually ends with `.gradio.live`)\n",
    "3. **Upload audio** or record from microphone\n",
    "4. **Choose mode:**\n",
    "   - **Bandwidth Extension**: Restore high frequencies (for low-quality MP3s)\n",
    "   - **Inpainting**: Fill in missing audio segments\n",
    "5. **Adjust settings** (optional):\n",
    "   - Sampling Steps: 25-100 (higher = better quality, slower)\n",
    "   - Auto Cutoff: Automatically detect cutoff frequency\n",
    "   - Inpainting Length: 0.1-1.0 seconds\n",
    "6. **Click \"üöÄ Restore\"** and wait for processing\n",
    "7. **Listen & Download** the restored audio\n",
    "\n",
    "**Tips:**\n",
    "- Start with default settings (50 steps, auto cutoff)\n",
    "- For faster results: 25-30 steps\n",
    "- For best quality: 75-100 steps\n",
    "- Processing time: ~2-3 minutes per 10 seconds of audio\n",
    "\n",
    "**‚ö†ÔøΩÔøΩ Important:**\n",
    "- Keep this notebook tab open during processing\n",
    "- Don't close the Colab session\n",
    "- If you get \"Out of Memory\" error, reduce sampling steps or audio length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gradio_app"
   },
   "outputs": [],
   "source": [
    "# Launch Gradio interface\n",
    "print(\"üöÄ Launching Gradio interface...\\n\")\n",
    "print(\"‚è±Ô∏è  Please wait for the link to appear below.\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python gradio_app.py\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Gradio interface launched!\")\n",
    "print(\"Click the link above to access the web interface.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "## üìö 5. Tips and Troubleshooting\n",
    "\n",
    "### ‚ö° Performance Optimization\n",
    "\n",
    "**GPU Requirements:**\n",
    "- ‚úÖ **Colab Pro**: T4 (16GB), V100 (32GB), or A100 (40GB)\n",
    "- ‚ö†Ô∏è **Free Colab**: May work but expect Out of Memory errors\n",
    "\n",
    "**Processing Times (on T4 GPU):**\n",
    "- 10 seconds audio, 50 steps: ~2-3 minutes\n",
    "- 30 seconds audio, 50 steps: ~5-7 minutes\n",
    "- 60 seconds audio, 50 steps: ~10-15 minutes\n",
    "\n",
    "### üéØ Quality Settings\n",
    "\n",
    "**Sampling Steps:**\n",
    "- **25-30:** Fast (good quality)\n",
    "- **50-75:** Balanced (excellent quality) ‚≠ê Recommended\n",
    "- **75-100:** Best (outstanding quality)\n",
    "\n",
    "**Cutoff Frequency (Bandwidth Extension):**\n",
    "- **Auto-detect**: Usually best ‚≠ê Recommended\n",
    "- **Manual adjustment:**\n",
    "  - Low-quality MP3: 2000-4000 Hz\n",
    "  - Medium quality: 4000-8000 Hz\n",
    "  - High quality: 8000+ Hz\n",
    "\n",
    "**Inpainting Length:**\n",
    "- 0.1-0.3s: Small gaps or clicks\n",
    "- 0.3-0.5s: Medium gaps\n",
    "- 0.5-1.0s: Large missing segments\n",
    "\n",
    "### üîß Troubleshooting\n",
    "\n",
    "#### ‚ùå CUDA Out of Memory Error\n",
    "\n",
    "**Solutions:**\n",
    "1. **Reduce sampling steps** to 25-30\n",
    "2. **Split audio** into shorter segments (10-20 seconds)\n",
    "3. **Restart runtime**: Runtime > Restart runtime\n",
    "4. **Clear GPU memory**: Run the cell below\n",
    "5. **Upgrade to Colab Pro** for better GPUs\n",
    "\n",
    "```python\n",
    "# Clear GPU memory\n",
    "import gc\n",
    "import torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "print(\"‚úÖ GPU memory cleared\")\n",
    "```\n",
    "\n",
    "#### ‚ùå Model Not Found Error\n",
    "\n",
    "**Solutions:**\n",
    "1. Re-run the model download cells (Section 2)\n",
    "2. Check your internet connection\n",
    "3. Verify files exist:\n",
    "```python\n",
    "!ls -lh ckpt/\n",
    "```\n",
    "\n",
    "#### ‚ùå Gradio Interface Not Loading\n",
    "\n",
    "**Solutions:**\n",
    "1. Wait 30-60 seconds for the link to appear\n",
    "2. Check if the cell is still running\n",
    "3. Restart runtime and run all cells again\n",
    "\n",
    "#### ‚ùå Audio Format Error\n",
    "\n",
    "**Solution:** Convert to WAV format\n",
    "```python\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# Convert any audio to WAV\n",
    "y, sr = librosa.load('input.mp3', sr=44100)\n",
    "sf.write('input.wav', y, sr)\n",
    "```\n",
    "\n",
    "#### ‚ö†Ô∏è Session Timeout\n",
    "\n",
    "**Solutions:**\n",
    "1. **Colab Pro**: Longer session times\n",
    "2. Keep the tab active\n",
    "3. Process shorter audio files\n",
    "4. Save intermediate results\n",
    "\n",
    "### üí° Best Practices\n",
    "\n",
    "1. **Start small**: Test with 10-20 second clips first\n",
    "2. **Use defaults**: 50 steps, auto cutoff works well\n",
    "3. **Monitor GPU**: Check `nvidia-smi` if issues occur\n",
    "4. **Save outputs**: Download restored audio immediately\n",
    "5. **Batch processing**: Process multiple files one at a time\n",
    "\n",
    "### üìñ License and Usage\n",
    "\n",
    "- **Model:** NVIDIA OneWay NonCommercial License\n",
    "- **Code:** NVIDIA Source Code License - Non Commercial\n",
    "- **Commercial Use:** Contact NVIDIA for licensing\n",
    "- **Research Use:** Free for academic and research purposes\n",
    "\n",
    "### üîó Additional Resources\n",
    "\n",
    "- **Paper:** [arXiv:2501.11311](https://arxiv.org/abs/2501.11311)\n",
    "- **GitHub:** [test4373/diffusion-audio-restoration](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- **Original NVIDIA Repo:** [NVIDIA/diffusion-audio-restoration](https://github.com/NVIDIA/diffusion-audio-restoration)\n",
    "- **Demo:** [NVIDIA Research](https://research.nvidia.com/labs/adlr/A2SB/)\n",
    "- **Models:** [HuggingFace](https://huggingface.co/nvidia/audio_to_audio_schrodinger_bridge)\n",
    "\n",
    "### üìß Support\n",
    "\n",
    "- **Issues:** [GitHub Issues](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-/issues)\n",
    "- **Original NVIDIA Issues:** [NVIDIA GitHub](https://github.com/NVIDIA/diffusion-audio-restoration/issues)\n",
    "\n",
    "---\n",
    "\n",
    "### üéâ Thank You!\n",
    "\n",
    "Thank you for using this notebook!\n",
    "\n",
    "**Citation:**\n",
    "```bibtex\n",
    "@article{kong2025a2sb,\n",
    "  title={A2SB: Audio-to-Audio Schrodinger Bridges},\n",
    "  author={Kong, Zhifeng and Shih, Kevin J and Nie, Weili and Vahdat, Arash and Lee, Sang-gil and Santos, Joao Felipe and Jukic, Ante and Valle, Rafael and Catanzaro, Bryan},\n",
    "  journal={arXiv preprint arXiv:2501.11311},\n",
    "  year={2025}\n",
    "}\n",
    "```\n",
    "\n",
    "### ‚≠ê Support This Project\n",
    "\n",
    "If you find this project useful:\n",
    "- ‚≠ê Star the [GitHub repository](https://github.com/test4373/diffusion-audio-restoration-colab-Kaggle-.git)\n",
    "- üêõ Report bugs or suggest features\n",
    "- üì¢ Share with others who might benefit\n",
    "\n",
    "---\n",
    "\n",
    "**Made with ‚ù§Ô∏è for the audio restoration community**\n",
    "\n",
    "**Optimized for Google Colab Pro with GPU memory management and user-friendly interface**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
